{"meta":{"title":"Hexo","subtitle":"","description":"","author":"张舒俞","url":"http://gladiouszhang.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2024-11-07T15:47:40.182Z","updated":"2024-07-30T17:49:16.000Z","comments":false,"path":"/404.html","permalink":"http://gladiouszhang.github.io/404.html","excerpt":"","text":""},{"title":"关于","date":"2025-01-08T03:19:32.516Z","updated":"2025-01-08T03:19:32.516Z","comments":false,"path":"about/index.html","permalink":"http://gladiouszhang.github.io/about/index.html","excerpt":"","text":"爱好徒步🥾🚶‍♂️🌲|书法✒️🖋️📜|摄影📷🎞️🖼️|阅读📚📖🔖|编程💻🖥️👨‍💻 我的对象 学习经历 2020-2024 本科 就读于西安电子科技大学 2024至今 硕士 就读于西安电子科技大学 目前关注的领域是分布式系统、边缘计算、区块链技术 论文发表 学生二作：Cortex: Enhancing Resource Utilization in Edge Clusters through Efficient Co-location of LC and BE Workloads，Internet of Things Journal 实习经历 2024年5月-2024年9月，西安言古科技有限责任公司，全栈开发。 主要获奖经历 学科竞赛： 2021年： 美国大学生数学建模竞赛特等奖提名奖 校星火杯三等奖 校创新创业竞赛铜奖 2022年： 美国大学生数学建模竞赛一等奖 校星火杯二等奖 大学生创新创业竞赛国家级立项（负责人） 2023年： 大学生创新创业竞赛国家级优秀结项（第二完成人） 省级互联网+铜奖 荣誉称号 2021年： 优秀共青团员 校优秀学生 校一等奖学金 2022年： 校十佳团支部书记 校优秀学生 校二等奖学金 掌趣科技奖学金 2023年： 校优秀学生 校一等奖学金 2024年： 校优秀团干部 毕业生二等奖学金 志愿经历： 蓝信封志愿者 抗疫志愿者"},{"title":"分类","date":"2024-11-07T15:47:40.301Z","updated":"2024-07-30T17:49:16.000Z","comments":false,"path":"categories/index.html","permalink":"http://gladiouszhang.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2024-11-07T15:47:40.537Z","updated":"2024-07-30T17:49:16.000Z","comments":false,"path":"tags/index.html","permalink":"http://gladiouszhang.github.io/tags/index.html","excerpt":"","text":""},{"title":"书单","date":"2024-11-07T15:47:40.278Z","updated":"2024-07-30T17:49:16.000Z","comments":false,"path":"books/index.html","permalink":"http://gladiouszhang.github.io/books/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2024-11-07T15:47:40.495Z","updated":"2024-07-30T17:49:16.000Z","comments":true,"path":"links/index.html","permalink":"http://gladiouszhang.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2024-11-07T15:47:40.517Z","updated":"2024-07-30T17:49:16.000Z","comments":false,"path":"repository/index.html","permalink":"http://gladiouszhang.github.io/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"强化学习SAC算法流程及与PPO对比","slug":"强化学习SAC算法流程及与PPO对比","date":"2025-03-05T13:53:26.000Z","updated":"2025-03-05T16:40:56.185Z","comments":true,"path":"2025/03/05/强化学习SAC算法流程及与PPO对比/","permalink":"http://gladiouszhang.github.io/2025/03/05/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0SAC%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B%E5%8F%8A%E4%B8%8EPPO%E5%AF%B9%E6%AF%94/","excerpt":"","text":"SAC算法流程 主循环中进行动作选择与环境交互 update函数当中 目标Q值计算（Critic更新） Actor策略更新 目标critic网络软更新 参考代码 和PPO算法进行对比 因为最近论文里面用到了这个算法，所以顺便也总结一下 SAC算法流程 主循环中进行动作选择与环境交互 Actor网络（策略网络$\\pi_{\\theta}$）根据当前状态$s_t$生成带随机性的动作$a_t \\sim \\pi_{\\theta}(\\cdot|s_t)$ 执行动作$a_t$，环境返回下一状态$s_{t + 1}$和奖励$r_t$ update函数当中 目标Q值计算（Critic更新） 双Q网络（Q1, Q2）：分别计算当前状态-动作对的Q值（$Q_{current}$）。 目标Q值（Q_target）： 下一状态输入Actor（就是策略网络 $\\pi_{\\theta}$）得到新动作$a’$及对应熵，也就是说 $ \\pi_{\\theta}(a’|s_{t + 1}) $ 实际上代表的是在下一状态时选择$a’$的概率。 用目标Critic网络（非训练参数）计算下一动作的Q值，并加熵项： $$Q^{\\text{target}} = r_t + \\gamma(1 - \\text{done})\\left[\\min_{j = 1,2}Q_{\\phi_{\\text{target}_j}}(s_{t + 1}, a’) - \\alpha \\log \\pi_{\\theta}(a’|s_{t + 1})\\right]$$ $a’ \\sim \\pi_{\\theta}(\\cdot|s_{t + 1})$ 表示由当前Actor网络根据状态 $s_{t + 1}$ 生成下一个动作。 $\\min_{j = 1,2}$ 是从两个目标Critic网络 $Q_{\\phi_{\\text{target}_1}}, Q_{\\phi_{\\text{target}_2}}$ 输出的值中取最小值，目的是避免高估Q值。 $\\alpha$ 是熵调节系数，$-\\log \\pi_{\\theta}(a’|s_{t + 1})$ 表示动作的熵，用于衡量动作的随机性。$\\log \\pi_{\\theta}(a’|s_{t + 1})$ 表示动作$a’$在当前策略下的对数概率（log probability），负号是为了将熵定义为正数。熵越大，表示动作的随机性越强（探索性越高）。其实这里应该暗含了，如果选择这个动作的可能性越小，那么Q_target就越小，也就更不愿意选择这个动作 其实我很困惑，为什么不是 $$Q^{\\text{target}} = r_t + \\gamma(1 - \\text{done})\\left[\\min_{j = 1,2}Q_{\\phi_{\\text{target}_j}}(s_{t + 1}, a’) - (-\\alpha \\log \\pi_{\\theta}(a’|s_{t + 1}))\\right]$$ 因为熵是$-\\log \\pi_{\\theta}(a’|s_{t + 1})$ ，肯定为正数，而原式想表达的是减去熵，但是如果不是像我这样写的话，实际上会加上熵？除非$\\alpha$是负数 最小化Q_current与Q_target的MSE损失，更新critic参数。 Actor策略更新 通过当前状态采样动作，计算更新后的critic和未更新的target_critic的Q值（取双Q最小值）并加熵项： $\\mathcal{L}_{\\text{actor}} = - \\left[\\min_{j = 1,2}Q_{\\phi_j}(s_t, \\tilde{a}_t) - \\alpha \\log \\pi_{\\theta}(\\tilde{a}_t|s_t)\\right], \\quad \\tilde{a}_t \\sim \\pi_{\\theta}(\\cdot|s_t)$ 使用优化器来最小化loss，因为取的是相反数所以实则是最大化该值，以提升策略性能与探索性。 通过梯度上升优化 $\\theta$，使动作 $\\tilde{a}_t$ 同时满足： 高Q值（Critic认可的动作） 高熵（鼓励探索，避免策略固化） 目标critic网络软更新 目标Critic参数通过Polyak平均缓慢跟踪主Critic $\\phi_{\\text{targ},i} \\leftarrow \\tau\\phi_{i} + (1 - \\tau)\\phi_{\\text{targ},i} \\quad (i = 1,2)$ 其中： $\\tau \\ll 1$（例如 0.005），该参数用于控制更新的幅度。通过这种软更新的方式，将当前网络参数 $\\phi_{i}$ 与目标网络参数 $\\phi_{\\text{targ},i}$ 进行融合，缓慢同步参数，目的是为了稳定训练过程，避免因参数更新过快导致训练不稳定。 参考代码 虽然这个代码没有考虑熵，以及没考虑两个Q的最小值，并且运行起来没啥结果，但是其他地方我都注释好了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194import torchimport torch.nn as nnimport torch.optim as optimimport numpy as np# --------------------------# 状态编码器（极坐标转换 + 特征拼接）# --------------------------def encode_state(vehicle_pos, vehicle_speed, nodes_info): &quot;&quot;&quot; 输入: vehicle_pos: 车辆当前位置 (笛卡尔坐标) [x, y] vehicle_speed: 车辆速度向量 [vx, vy] nodes_info: 边缘节点信息列表，每个元素为 [节点x, 节点y, 计算能力, 信任度] 输出: state_tensor: 编码后的状态张量 (shape: [1, state_dim]) &quot;&quot;&quot; # 将车辆与节点的相对位置转换为极坐标 polar_features = [] for node in nodes_info: dx = node[0] - vehicle_pos[0] dy = node[1] - vehicle_pos[1] r = np.sqrt(dx ** 2 + dy ** 2) # 相对距离 theta = np.arctan2(dy, dx) # 相对角度（弧度） polar_features.extend([r, theta]) # 速度投影（径向和切向分量） speed_norm = np.linalg.norm(vehicle_speed) if speed_norm &gt; 0: v_r = (vehicle_speed[0] * dx + vehicle_speed[1] * dy) / (r + 1e-5) # 径向速度 v_theta = (vehicle_speed[0] * dy - vehicle_speed[1] * dx) / (r + 1e-5) # 切向速度 else: v_r, v_theta = 0.0, 0.0 # 假设LSTM隐藏状态（简化为随机向量） lstm_hidden = np.random.randn(16) # 拼接所有特征 state = np.concatenate([ polar_features, [v_r, v_theta], lstm_hidden, [node[2] for node in nodes_info], # 节点计算能力 [node[3] for node in nodes_info] # 节点信任度 ]) return torch.FloatTensor(state).unsqueeze(0)# --------------------------# Actor网络（策略网络）# --------------------------class Actor(nn.Module): def __init__(self, state_dim, action_dim, hidden_dim=256): super().__init__() self.net = nn.Sequential( nn.Linear(state_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, action_dim), nn.Tanh() # 输出范围[-1,1]，需映射到具体动作 ) def forward(self, state): return self.net(state)# --------------------------# Critic网络（Q函数）# --------------------------class Critic(nn.Module): def __init__(self, state_dim, action_dim, hidden_dim=256): super().__init__() self.q_net = nn.Sequential( nn.Linear(state_dim + action_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 1) ) def forward(self, state, action): return self.q_net(torch.cat([state, action], dim=1))# --------------------------# ST-SAC主类# --------------------------class ST_SAC: def __init__(self, state_dim, action_dim, lr=3e-4, gamma=0.99, alpha=0.2, tau=0.005): # 主网络 self.actor = Actor(state_dim, action_dim) self.critic = Critic(state_dim, action_dim) self.critic_target = Critic(state_dim, action_dim) # 新增目标网络 self.critic_target.load_state_dict(self.critic.state_dict()) # 同步初始化 # 优化器 self.actor_optim = optim.Adam(self.actor.parameters(), lr=lr) self.critic_optim = optim.Adam(self.critic.parameters(), lr=lr) # 超参数 self.gamma = gamma self.alpha_base = alpha self.tau = tau # 目标网络软更新系数 def select_action(self, state, nodes_info, trust_threshold=0.5): &quot;&quot;&quot; 选择动作（含安全掩码） &quot;&quot;&quot; with torch.no_grad(): action = self.actor(state) # 生成动作掩码（信任度 &gt;= 阈值） valid_nodes = [i for i, node in enumerate(nodes_info) if node[3] &gt;= trust_threshold] mask = torch.zeros_like(action) for i in valid_nodes: mask[:, i] = 1.0 # 假设每个动作维度对应一个节点 # 应用掩码并随机探索 masked_action = action * mask + (1 - mask) * torch.randn_like(action) return masked_action.squeeze(0).numpy() def update(self, state, action, reward, next_state, done, vehicle_speed): # 动态熵系数 v_r = abs(state[0, -len(nodes_info) * 2 + 1]) alpha = self.alpha_base * (1 + torch.sigmoid(torch.tensor(v_r))) # ----------------- 1. Critic 更新 ----------------- with torch.no_grad(): next_action = self.actor(next_state) # 使用目标网络计算目标Q值 target_q = self.critic_target(next_state, next_action) # 当前动作的即时奖励 + 对未来奖励的预测 target_q = reward + (1 - done) * self.gamma * target_q current_q = self.critic(state, action) # 目标：让当前Q值逼近目标Q值 critic_loss = nn.MSELoss()(current_q, target_q) self.critic_optim.zero_grad() critic_loss.backward() # 更新critic网络，让网络参数往目标Q值的方向更新 self.critic_optim.step() # ----------------- 2. Actor 更新 ----------------- # 切断Critic到Actor的梯度传播 pred_action = self.actor(state) # actor网络的参数更新需要依赖critic网络的输出,critic是更新过的，用来给actor提供指导 # detach()的作用是剥离出一个相同值但不包含梯度的Variable，不参与计算图的构建 q_value = self.critic(state, pred_action).detach() # 关键：detach(),detach()后的梯度不会传播到actor actor_loss = -q_value.mean() + alpha * (pred_action ** 2).mean() self.actor_optim.zero_grad() actor_loss.backward() self.actor_optim.step() # ----------------- 3. 目标网络软更新 ----------------- # 把critic的value更新到target_critic for t_param, param in zip(self.critic_target.parameters(), self.critic.parameters()): t_param.data.copy_(self.tau * param.data + (1 - self.tau) * t_param.data)# --------------------------# 示例使用# --------------------------if __name__ == &quot;__main__&quot;: # 假设场景：1辆车，3个边缘节点 vehicle_pos = [0.0, 0.0] vehicle_speed = [1.0, 0.0] # 沿x轴移动 nodes_info = [ [10.0, 0.0, 5.0, 0.8], # 节点1：正前方，高信任 [0.0, 5.0, 3.0, 0.3], # 节点2：左侧，低信任 [-5.0, 0.0, 4.0, 0.6] # 节点3：后方，中等信任 ] # 初始化ST-SAC state_dim = len(encode_state(vehicle_pos, vehicle_speed, nodes_info).squeeze(0)) action_dim = len(nodes_info) # 每个动作维度对应一个节点的卸载选择 agent = ST_SAC(state_dim, action_dim) # 示例训练步骤 state = encode_state(vehicle_pos, vehicle_speed, nodes_info) for _ in range(100): # 用到了actor action = agent.select_action(state, nodes_info) next_vehicle_pos = [vehicle_pos[0] + 0.1, vehicle_pos[1]] # 模拟移动 next_state = encode_state(next_vehicle_pos, vehicle_speed, nodes_info) reward = -np.abs(action).mean() # 示例奖励：鼓励集中卸载 done = False agent.update(state, torch.FloatTensor(action).unsqueeze(0), torch.FloatTensor([reward]), next_state, done, vehicle_speed) state = next_state 和PPO算法进行对比","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://gladiouszhang.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"强化学习","slug":"强化学习","permalink":"http://gladiouszhang.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"}]},{"title":"CMU-深度学习系统-第二章","slug":"CMU-深度学习系统-第二章","date":"2025-03-02T05:39:06.000Z","updated":"2025-03-02T07:53:29.656Z","comments":true,"path":"2025/03/02/CMU-深度学习系统-第二章/","permalink":"http://gladiouszhang.github.io/2025/03/02/CMU-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F-%E7%AC%AC%E4%BA%8C%E7%AB%A0/","excerpt":"","text":"这章是用softmax的例子来回顾了ML的知识点。 softmax回归又叫多类逻辑回归，就是将输入数据进行分类，通过softmax函数得到每个类别的概率。 而这样的分类问题，是通过实现准备这样一个数据集：包含数据和数据对应的标签。让模型学习数据集和标签的对应关系，这样的过程叫做监督学习。 除了监督学习，还有 无监督学习 数据没有标签，模型从无标签数据中发现隐藏模式或结构。 如K-means、层次聚类、主成分分析（PCA） 半监督学习（Semi-Supervised Learning） 结合少量有标签数据和大量无标签数据训练模型。 适用于标注成本高，但未标注数据丰富（如医学图像分析）。 强化学习（Reinforcement Learning, RL） 模型通过与环境交互，根据奖励信号调整策略，目标是最大化长期累积奖励。 适用于序列决策问题（如机器人控制、游戏AI）。 Q-learning、深度强化学习（DQN）、策略梯度（PPO）。 自监督学习（Self-Supervised Learning） 通过构造“伪标签”从无标签数据中学习，属于无监督学习的子类。 NLP中的预训练模型（如BERT通过掩码预测学习上下文）。 图像中的对比学习（如SimCLR通过图像增强构造正负样本对）。 多任务学习（Multi-Task Learning） 同时学习多个相关任务，共享部分模型参数以提高泛化能力。 一个模型同时完成文本分类和实体识别。 无论是怎么样的机器学习，都一定会包含三个要素 hypothesis class，也就是模型的结构 loss函数 优化方法 比如k分类问题，输入数字的图像，输出的是每个数字的一种可能性（这里还不能说是概率，因为不满足概率的条件） 为什么要用矩阵：数学上更严谨，同时有利于并行计算提高效率。 loss函数是为了对比输出的结果和原本标签之间的差距。一个最简单的loss函数： 但是这个函数并不好，因为不可导。 进一步我们把上面提到的输出的可能性转化为概率，而这一步就是softmax函数： 其中 $z_i$就是每一个类别的概率。之所以叫softmax回归应该也是因为这个softmax函数。 根据这个转化后的概率，可以进一步得到loss的计算公式，也就是softmax loss或者叫做交叉熵损失。 为什么要用负对数？ 其中$h_y(x)$应该是对应x输入时为y的概率值，k是k分类的k 目前常用的优化方法是SGD，就是随机梯度下降，因为如果对全体对象进行梯度下降，空间太大了。SGD是进行多轮，每次抽取一定样本来进行更新。","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://gladiouszhang.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"AI Infa","slug":"AI-Infa","permalink":"http://gladiouszhang.github.io/tags/AI-Infa/"}]},{"title":"higher库在元（强化）学习中的使用","slug":"higher库在元（强化）学习中的使用","date":"2024-11-11T06:28:49.000Z","updated":"2024-11-11T08:59:49.581Z","comments":true,"path":"2024/11/11/higher库在元（强化）学习中的使用/","permalink":"http://gladiouszhang.github.io/2024/11/11/higher%E5%BA%93%E5%9C%A8%E5%85%83%EF%BC%88%E5%BC%BA%E5%8C%96%EF%BC%89%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"higher.innerloop_ctx是higher库的上下文管理器，用于创建内部循环（inner loop）的上下文，内部循环通常用于元学习场景，其中在模型参数更新的内部循环中进行一些额外的操作。 12higher.innerloop_ctx(model, opt, device=None, copy_initial_weights=True, override=None, track_higher_grads=True) 第一个参数model是需要进行内部循环的模型，通常是你的元模型。这个内部循环只是作为临时更新，结束内部循环后更新元模型真正的参数。 第二个参数opt是优化器，这是你用来更新模型参数的优化器 第三个参数copy_initial_weights是一个布尔值，copy_initial_weights=True 的作用是在进入内部循环上下文时，仅仅在一开始将 model 的参数拷贝一份到 fmodel 中。而在上下文期间的内部循环中，fmodel 的参数会持续累积更新，而不会在每次循环前被重新初始化；当 copy_initial_weights=False 时，higher.innerloop_ctx 不会在创建 fmodel 时复制 model 的参数。相反，fmodel 将直接引用 model 的参数。这意味着在内部循环中对 fmodel 的任何更新都会直接影响到 model 的参数。 第四个参数override是一个字典，例如override={‘lr’:lr_tensor, &quot;momentum’: momentum_tensor}，用于指定在内部循环期间覆盖元模型优化器（即第二个参数opt）的参数，即给内外进行一个隔离。 第五个参数track_higher_grads是一个布尔值，用于跟踪更高阶的梯度，如果是True，则内部循环中计算的梯度将被跟踪以支持高阶的梯度计算，这对于实现元学习算法（例如 MAML）是必要的，因为 MAML 需要计算“关于初始参数的梯度的梯度”。如果设置为False，则不会跟踪高阶梯度。 在 MAML 中，我们的目标是找到一组初始参数，使模型能在不同任务的内部循环中快速适应。为了实现这一点，MAML 的外部循环需要对内部循环的更新进行微分，计算出高阶梯度。这使得元模型能够逐步优化其初始参数，以便在未来任务上更快地适应。 gpt给出了一个基于higer的强化学习示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475import torchimport torch.nn as nnimport torch.optim as optimimport higher# 定义一个简单的线性模型class SimpleModel(nn.Module): def __init__(self): super(SimpleModel, self).__init__() self.linear = nn.Linear(1, 1) def forward(self, x): return self.linear(x)# 生成模拟任务，每个任务都有一个不同的线性关系def generate_task(): # 随机生成斜率和偏置 slope = torch.randn(1) intercept = torch.randn(1) # 随机生成5个训练样本 x_train = torch.rand(5, 1) y_train = slope * x_train + intercept # 随机生成5个测试样本 x_test = torch.rand(5, 1) y_test = slope * x_test + intercept return (x_train, y_train), (x_test, y_test)# MAML的核心参数meta_lr = 0.001 # 外部循环学习率inner_lr = 0.01 # 内部循环学习率inner_steps = 1 # 每个任务的内部循环步数meta_batch_size = 4 # 每次元更新的任务数量# 创建模型和元学习优化器model = SimpleModel()meta_optimizer = optim.Adam(model.parameters(), lr=meta_lr)# 元学习训练过程for meta_step in range(1000): # 总的元学习步骤数 meta_optimizer.zero_grad() meta_loss = 0 # 每次从不同的任务中采样 for _ in range(meta_batch_size): # 生成任务的训练和测试数据 (x_train, y_train), (x_test, y_test) = generate_task() # 使用 higher.innerloop_ctx 创建内部循环上下文 with higher.innerloop_ctx(model, opt=optim.SGD(model.parameters(), lr=inner_lr), copy_initial_weights=True) as (fmodel, diffopt): # 内部循环更新：在任务训练数据上进行 inner_steps 次更新 for _ in range(inner_steps): train_pred = fmodel(x_train) train_loss = nn.functional.mse_loss(train_pred, y_train) diffopt.step(train_loss) # 计算任务验证损失，用于外部循环的更新 test_pred = fmodel(x_test) test_loss = nn.functional.mse_loss(test_pred, y_test) # 累加所有任务的验证损失 meta_loss += test_loss # 计算每个任务的平均验证损失，并对元模型进行反向传播 meta_loss /= meta_batch_size meta_loss.backward() meta_optimizer.step() if meta_step % 100 == 0: print(f&quot;Meta Step &#123;meta_step&#125;, Meta Loss: &#123;meta_loss.item()&#125;&quot;)print(&quot;Meta-learning finished!&quot;) 我认为核心是： 在外部定义一个元模型和优化器，定义元强化学习外循环的训练次数。 再定义需要多少个不同的任务。 对于每个不同的任务，再进行多次内循环。 在内循环内部借助元模型和优化器（可以覆盖部分参数）进行多轮训练。 每轮训练结束后进行参数更新 内循环结束后在验证集上进行验证，得到loss 累计所有的loss 对元模型使用平均后的loss进行更新","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://gladiouszhang.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}]},{"title":"阅读MapReduce","slug":"阅读MapReduce","date":"2024-11-07T14:49:34.000Z","updated":"2024-11-17T09:38:50.337Z","comments":true,"path":"2024/11/07/阅读MapReduce/","permalink":"http://gladiouszhang.github.io/2024/11/07/%E9%98%85%E8%AF%BBMapReduce/","excerpt":"","text":"摘要 介绍 编程模型 例子 类型 更多例子 分布式grep（查找某个单词） URL访问频次统计 反向web连接图 每个主机的词向量 倒排索引 分布式排序 实现 执行概述 Master的数据结构 错误容忍 worker失效（failure） master失效 在故障情况下的语义（？） 本地性 任务粒度 备份任务 改良 分区函数（Partition） 顺序保证 合并函数 输入输出类型 副作用 跳过坏记录 本地执行 状态信息 计数器 性能 集群配置 Grep操作 排序操作 备份任务的影响 机器失败的影响 全部读了一遍，除了实践以外都做了笔记 摘要 map：用来处理键值对来生成一组中间键值对 reduce：合并同一相同中间键相关联的中间值 介绍 用途举例：倒排索引、web文档的图形化表示等。 操作简单，但是数据量大，需要多台机器并行计算。 问题：如何并行化计算、分发数据、处理故障 使用用户指定的map和reduce操作，用重新执行作为容错的机制 编程模型 map函数：由用户编写，输入一个对，然后输出一组中间键值对。MapReduce库会把所有具有相同key的中间键值对组合起来，然后发给Reduce函数处理。 reduce函数：也是由用户编写。接受中间键 I 和该键的一组值。它将这些值合并在一起以形成可能数量更小的一组值。通常reduce操作只产生0或1个值。中间值通过迭代器提供给用户的 Reduce 函数。这使我们能够处理太大而无法放入内存的值列表。 例子 统计单词词频： map把所有的单词作为key，value分别设为1 reduce把相同key的value相加，输出结果 用户编写具体的代码实现填充到mapreduce specification对象中，然后把用户的代码和MapReduce库链接在一起实现。 类型 map 和 reduce 函数的输入和输出类型在概念上是不同的，但在 C++ 实现中，通过字符串来统一传递数据。 用户需要在代码中处理字符串和实际数据类型之间的转换。 更多例子 分布式grep（查找某个单词） 如果某一行满足提供的范式，map函数就把它发出。reduce只是把它拷贝一遍。 URL访问频次统计 map函数统计网站请求日志，并输出为&lt;url,1&gt;，reduce把后面的数值加起来 反向web连接图 在resource界面找到的target的url，经过map函数，输出&lt;target，resource&gt;对。reduce把resource整理成list，输出&lt;target,list(resource)&gt; 每个主机的词向量 词向量总结了一个或多个文件中最重要的单词的出现频率，是由&lt;word,frequency&gt;组成的列表。map从输入文件中读入hostname，输出&lt;hostname,term vector&gt;。reduce函数将每一个hostname的term vector合并并输出。 倒排索引 就是说找到单词的位置。map输出&lt;word, 文件id&gt;，reduce把文件id合成一个list 分布式排序 map函数从每一个记录中提取出key，输出&lt;key,record&gt;对，reduce啥也不变。排序取决于后面提到的分区工具和排序属性（稍后来填坑） 实现 MapReduce接口有许多不同的实现。正确的选择取决于环境。这节描述了一个针对Google广泛使用的计算环境的实现:用交换式以太网连接在一起的大型商用PC集群。 执行概述 通过将输入数据自动划分为一组M个部分，map函数调用分布在多台机器上。输入拆分可以由不同的机器并行处理。通过使用分区函数(例如，hash(key) mod R)将中间密钥空间划分成R个部分，来分布Reduce调用。分区数量®和分区函数由用户指定。 MapReduce库首先将输入文件分成M段，每段通常16MB-64MB，然后在集群的机器上开启程序的许多副本（图中fork成worker和master）。 其中有一个特殊的副本叫master，其他的都是被master分配工作的worker。有M个映射任务和R个归约任务要分配。master挑选空闲的worker来分配一个map任务或者一个reduce任务 被分配了map的worker读取相应输入分割的内容。它从输入数据中解析出键/值对，并将每一对传递给用户定义的reduce函数。Map函数产生的中间键/值对在内存中缓冲。 缓存的pair被周期性的写到本地磁盘。由分区函数（前面提到的hash取余）划分成R个区域。这些缓冲对在本地磁盘上的位置被传递回master，主设备负责将这些位置转发给reduce工作器。 当mater通知reduce worker这些位置时，它使用rpc从map workers的本地磁盘读取缓冲数据。当reduce worker读取了所有的中间数据后，它会按照中间键对数据进行排序，以便将所有出现的相同键组合在一起。需要进行排序是因为通常许多不同的键映射到同一个reduce任务，为了确保相同的键的所有值被分组在一起，这有助于 Reduce 阶段对这些键进行集中处理。如果中间数据量太大，不适合内存，就使用外部排序（？）。 如果中间数据量非常大，无法完全放入内存中进行排序，这时候就需要使用外部排序（External Sort）。外部排序 是一种用于处理超大规模数据的排序方法，因为这些数据太大而无法一次性加载到内存中。外部排序的典型做法是将数据分块处理，将每个块单独排序后写回磁盘，最后将所有已排序的块合并起来，形成一个最终有序的数据集。在这个过程中，Reduce 节点会将无法容纳在内存中的数据分批次地进行排序和合并，直到所有数据都已经排序完成。这种排序策略对于处理超大规模数据非常有效。 reduce worker在排好序的中间数据上遍历，对于遇到的每个中间键（唯一的，不会重复发！），它会把键和值都发给reduce函数。reduce函数的输出被附加到这个Reduce分区的最终输出文件中。 当所有的map任务和reduce任务完成后，主机唤醒用户程序。此时，用户程序中的MapReduce调用返回到用户代码 最后用户得到R个输出文件，但是不一定会合并，因为会作为下一个输入（可能） Master的数据结构 master保存的数据结构：对于每个map和reduce任务，master保存其状态（空闲、进行中、完成）和非空闲状态任务的worker的身份。 master是用来讲map任务产生的中间文件传播到reduce任务的通道。所以master存着已完成的map任务的中间文件的位置和大小，如果有新的map任务完成会继续更新，并且用增量的方式推送到正在执行reduce任务的worker。 错误容忍 worker失效（failure） master间歇性ping worker。如果一段时间worker没回就是挂了。所有分到这个worker的map任务都会重新召回标记为空闲状态，进行重新调度。reduce也是类似的。就算是已完成的map任务，也会重新执行，因为他们的map中间结果在挂了的worker上。完成的reduce任务不需要重新执行，因为他们输出存储在全局文件系统中。 A挂了之后把map分给B时，所有的reduce worker都会收到这次A原本的工作执行的通知（因为不知道这个任务分给了哪个reduce worker，让所有人都知道要换个地方找）。 mapreduce能够容忍大规模的woker挂掉。 master失效 主节点周期性的写master数据结构的checkpoints。master挂了的话就从最后一个checkpoint开启一个副本。但因为只有一个master，不太可能故障。所以如果master故障的话会终止mapreduce。如果需要，客户端可以检查并重试MapReduce操作。 属于是技术上可以做但是没必要 在故障情况下的语义（？） 系统在出现故障时，计算程序所产生的行为和结果的定义。它探讨的是，系统中某些组件（比如某些节点或任务）如果出现故障，整个系统在处理任务时依然要保证的结果的正确性和一致性。 当用户提供的 map 和 reduce 操作是输入值的确定性函数时，mapreduce会生成与不发生故障的顺序执行整个程序时相同的输出。（就是说故障情况下结果依然是一样的）。这是依赖于map和reduce任务输出的原子提交：每个进行中的任务都将其输出写入私有临时文件。reduce任务产生一个这样的文件，map任务产生R个这样的文件(每个reduce任务一个)。当map任务完成时，worker向master发送一条消息，并在消息中包含R个临时文件的名称。如果主服务器收到已完成的map任务的完成消息，它将忽略该消息（可能原来挂了的复活了）。否则，它在主数据结构中记录R文件的名称。 假设我们有两个 Reduce worker，分别是 A 和 B，同时存在一个 Reduce 任务 R。下面是详细的流程描述，包括一个 worker 挂掉的过程。 初始分配任务 主节点将 Reduce 任务 R 分配给 worker A 执行。 worker A 开始执行这个 Reduce 任务，并逐步处理数据，将结果写入到一个临时文件 tempA 中。 任务执行过程中发生故障 假设 worker A 在执行过程中由于某种原因（例如硬件故障、网络断连等）突然挂掉，它无法完成任务。 主节点监控着所有任务的状态，发现 worker A 在规定的时间内没有汇报任务进度或完成情况，于是判断 worker A 失效。 主节点决定将 Reduce 任务 R 重新分配给另一个健康的 worker B 来执行。 新的任务分配给 worker B worker B 接到任务后，开始重新执行 Reduce 任务 R，它可能需要从中间数据中读取并计算，生成自己的临时文件 tempB。 worker B 最终完成了任务，并生成了临时文件 tempB，准备将其重命名为最终的输出文件 final_output。 worker A 恢复运行 在 worker B 正在执行任务时，之前挂掉的 worker A 突然恢复运行了。 恢复后的 worker A 会继续之前中断的工作，并试图完成它的 Reduce 任务。因此，worker A 最终也生成了它自己的临时文件 tempA。 两个 worker 竞争写入最终输出 现在我们有两个不同的 worker（A 和 B），它们都认为自己完成了 Reduce 任务 R，并且分别生成了两个不同的临时文件 tempA 和 tempB。 worker A 和 worker B 都会尝试将各自的临时文件重命名为最终的输出文件 final_output。 原子重命名操作的应用 在执行重命名时，底层文件系统的原子重命名操作起到了关键作用。 假设 worker B 先尝试重命名它的临时文件 tempB 为 final_output，由于重命名操作是原子的，worker B 成功地将 tempB 重命名为了 final_output。 由于文件系统的原子性，这个重命名操作是不可分割的，意味着此时最终的输出文件 final_output 已经确定下来，包含的是 worker B 的结果。 当 worker A 尝试重命名它的临时文件 tempA 为 final_output 时，发现这个名称已经存在，因此它的重命名操作会失败。 通过这种机制，最终的文件系统中只会保留一次任务的输出，并且最终的输出文件 final_output 中包含的是某一个 Reduce worker 成功执行后的数据（在这个例子中是 worker B 的数据）。 因为他们访问的是同一个全局命名空间，并且能够查看和操作相同的文件。 绝大部分情况下map和reduce是确定性的，这样的话程序相当于是并行的。如果map和/或ruduce是非确定性的，提供较弱但仍然合理的语义。在存在非确定性运算符的情况下，特定 Reduce 任务 R1 的输出相当于一个非确定性程序顺序执行产生的 R1 输出。但是，另一个 Reduce 任务 R2 的输出可能对应于非确定性程序的不同顺序执行产生的 R2 输出。（就是说执行顺序也许不同） 在非确定性操作中，多个 reduce 任务可能会读取来自 map 任务的不同执行结果，因此输出的顺序和内容可能不同，但每个 reduce 任务的输出仍然等价于它在顺序执行中可能得到的结果。 本地性 因为网络资源稀缺，输入数据用Google File System（GFS）管理，存储在机器的本地磁盘。GFS把每个文件被分为64MB的块，并将每个块存储多个副本（通常是3个副本）存到不同机器。master会考虑输入文件的位置，并尝试将一个 map 任务调度到包含相应输入数据副本的机器上。如果不行，master会尝试将 map 任务调度到一个靠近该任务输入数据副本的机器上（例如，调度到与包含数据副本的机器处于同一网络交换机上的 worker 机器）。因此，大部分数据读取是在本地。 任务粒度 map和reduce分别分为M和R个任务，都远大于worker的数量。每个worker执行多个不同的任务，这些任务是相互独立的。这样可以更好的负载均衡，并且可以加速worker挂了的时候的会复苏的，因为挂掉worker的任务可以快速分配到其他woker上。 实际上R和M大小有限制，因为master必须做O(M + R)次调度决策，并且需要在内存中保持O(M ∗ R)的状态信息（虽然每一对M和R的状态信息很小，1B左右）。R经常受用户约束（大概是用户指定的意思），所以一般限制M，让每个任务处理的输入数据大约为16 MB到64 MB，R为worker数量的一个小倍数。如果是2000台worker，那么通常设置M = 200,000和R = 5,000 备份任务 mapreduce中常见的延迟原因之一是straggler（拖延者），即一个机器在完成最后几个map或reduce任务时花费异常长的时间。 可能的原因：硬件问题（例如磁盘读写性能低下）、资源竞争（例如机器上有多个任务同时运行，导致资源不足）、甚至是软件故障（例如处理器缓存被禁用，导致性能急剧下降） 解决策略：设计了一套备份任务执行机制。当MapReduce操作接近完成时，master会调度剩余的正在进行的任务的备份执行。只要主任务或备份任务中的任何一个完成，任务就会被标记为已完成。 改良 感觉就是一些可修改的参数。 分区函数（Partition） 分区函数是对mapper产生的中间文件进行划分，分到reducer上面，默认是hash(key) mod R。通常够用了，但是有的用户想自定义，因为其他函数更有意义，比如有时输出键可能是URL，而我们希望相同hostname的所有条目都位于同一个输出文件中。例如，使用“hash(Hostname(urlkey)) mod R”作为分区函数，可以确保来自同一主机的所有URL条目都被划分到同一个输出文件。 顺序保证 中间键值对会按照键的递增顺序进行处理（MapReduce系统会保证在每个Reduce任务中，这些键值对按照键的递增顺序被排序），即reducer的输入递增。对于以下情况有意义： 当输出文件格式需要支持按键进行高效的随机访问查找时。 当输出的用户觉得数据按键排序更方便时。 合并函数 背景：每个map任务产生的中间件有时有显著重复，且reduce时可交换和可结合的。比如单词计数，每个Map任务会产生成百上千条为&lt;the, 1&gt;。但是对于reduce来说很浪费，因为全是一样的。因此用户可以事先指定一个combiner函数，在从mapper通过网络发送到reducer之前进行部分合并（减小网络开销）。 通常，Combiner函数和Reduce函数使用的是相同的代码，但是combiner产生的是中间文件，reducer产生的是最终文件。 输入输出类型 MapReduce库支持以多种不同格式读取输入数据： 文本（text）模式：每一行视为一个键/值对，键是文件中的偏移量，值是该行的内容。 按键的顺序存储：多个键/值对会根据键的大小顺序进行排序 比如输入： apple banana apple grape banana apple 1234567891011- mapper输出：- ``` (apple, 1) (apple, 1) (apple, 1) (banana, 1) (banana, 1) (grape, 1) 可以用一个reader接口来添加对新输入类型的支持（但是用户通常用预定义的那些就够了）。reader不一定从文件中读取数据，数据库、内存映射的数据结构也可以。 输出类似，同上所述。 副作用 （这里副作用感觉不一定是坏的那种意思） 用户可能希望同时能输出其他辅助文件，比如日志文件、调试信息。但是这个文件的输出（在这里被称为副作用）的原子性和幂等性应当由开发者自己保证。 原子性是指一个操作或一组操作要么完全成功，要么完全失败,强调操作的完整性 幂等性是指一个操作可以被执行多次，但无论执行多少次，最终的结果都是相同的。强调操作的重复性 通常，应用程序会将数据写入临时文件，并在文件完全生成后原子性地重命名该文件。 mapreduce不提供对单个任务生成的多个输出文件的原子两阶段提交的支持。所以如果要输出多个文件并且要保证以上两个性质，那么函数应当是确定性的。 如果某个任务生成多个输出文件（例如output1.txt和output2.txt），并且这两个文件之间有某种依赖关系（如output1.txt中的内容需要在output2.txt中引用），那么这个任务必须是确定性的：任务在每次运行时都应生成相同的文件内容，并且文件生成的顺序也应一致。这样，即使MapReduce框架没有支持原子两阶段提交，用户仍然能确保输出的可靠性。 什么是原子两阶段提交： 是一种分布式事务协议，旨在确保在分布式系统中，多个独立的参与者（例如多个数据库、服务器或服务）能够一致地完成某个事务的提交或回滚。这个协议的核心目标是保证分布式事务的原子性，即要么所有参与者都成功提交事务，要么所有参与者都回滚事务。 准备阶段（Phase 1 - Prepare Phase）： 协调者（通常是一个事务管理器）向所有参与者发送一个“准备提交”的请求，询问它们是否可以提交事务。 每个参与者（即执行任务的节点）检查自己能否成功提交事务。如果一切正常，参与者返回YES（准备提交）；如果有任何问题，参与者返回NO（无法提交）。 提交阶段（Phase 2 - Commit Phase）： 如果所有参与者都返回YES，即所有参与者都准备好了提交事务，那么协调者会发出一个提交（commit）命令，所有参与者将正式提交事务。 如果任何一个参与者返回NO，即某个节点无法提交事务，那么协调者会发出一个回滚（rollback）命令，要求所有参与者回滚已做的操作，确保整个事务不产生任何副作用。 跳过坏记录 代码里面的错误有可能会导致map和reduce在某些数据上崩溃，但是有时候这些代码不好改（比如调的别人的库）。有时忽略掉一些数据是可以接受的，比如数据量很大的那种大数据统计，少几个数据的影响很小。mapreduce库里提供了一种可选的执行模式，可以检测到导致确定性崩溃的记录，并跳过这些记录以确保任务能够继续进行。 具体流程： 崩溃检测： 每个工作进程（即执行Map或Reduce任务的机器）都会安装一个信号处理程序，用于捕捉崩溃信号（如段错误 segmentation fault 或总线错误 bus error）。 在每次执行Map或Reduce任务之前，MapReduce框架会记录当前正在处理的记录的序列号。 记录失败： 如果某个Map或Reduce任务由于某个特定的记录而崩溃，信号处理程序会捕获这个崩溃并发送一个UDP数据包给MapReduce的主节点。该数据包包含了导致崩溃的记录的序列号。 失败计数和跳过记录： MapReduce主节点收到多个崩溃报告后，识别出哪个记录导致了崩溃。如果某个记录多次引发崩溃，主节点会决定跳过该记录，并在重新调度Map或Reduce任务时不再处理该记录。 继续执行： 跳过导致崩溃的记录后，任务可以继续执行，而不会被这些问题数据阻塞。最终，MapReduce作业可以完成，虽然有些记录被忽略。 本地执行 因为完整的mapreduce过程很难调试map和reduce函数的问题，所以提出了在本地机器上顺序地执行MapReduce操作的所有任务的方式。这样，开发人员可以直接在本地环境中运行程序，并使用调试工具（如gdb）来追踪问题和调试代码。 状态信息 主节点运行一个内部HTTP服务器（所以上面那个跳过坏记录的可以发udp到master），提供实时的状态监控页面，给用户跟踪整个MapReduce作业的进度，还包含了每个任务生成的标准错误和标准输出文件的链接。 计数器 提供了一个计数器功能，允许用户在Map和Reduce函数中对不同的事件进行计数。可以帮助用户在运行MapReduce作业时进行数据验证、性能监控或行为分析。来自各个worker机器的计数器值会定期传递给主节点（通过ping响应传递）。计数器值也会显示在主节点的状态页面上，用户可以实时观察计算进度。计数器会消除相同map或reduce函数的影响。 使用方法： 创建计数器：用户通过调用GetCounter(&quot;name&quot;)来创建一个计数器对象，这个对象会以name作为标识符。 增加计数器值：在Map或Reduce函数中，用户可以使用Increment()方法增加计数器值。例如，在Word Count程序中，用户可以创建一个计数器来统计大写字母单词的数量。 性能 以大数据中寻找符合特定范式的数据和大数据排序两个例子来测量性能。这两个程序代表了MapReduce用户编写的实际程序的一个大子集——一类程序将数据从一种表示变换到另一种表示，另一类程序从大数据集中提取少量有趣的数据。 集群配置 1800台机器，其他不想赘述（ Grep操作 扫描一个$10^{10}$条的100Byte的记录，从中找一个罕见的三字符的范式，出现了92337次。输入被分成大约 64MB 的块（M = 15000），整个输出放在一个文件中（R = 1） Y轴表示输入数据的扫描速率。随着更多的机器被分配到这个MapReduce计算任务，扫描速率逐渐提高，当分配了1764个工作节点时，扫描速率达到超过30 GB/s的峰值。 随着Map任务的完成，速率开始下降，并在计算开始后的约80秒时降为零，表示所有Map任务都已经完成。整个计算过程大约持续了150秒，包括大约1分钟的启动开销。这个启动开销主要是由于程序传播到所有工作节点，以及与GFS（Google文件系统）交互的延迟——需要打开1000个输入文件并获取本地优化所需的信息。 排序操作 数据：$10^{10}$个 100Byte的记录，大约1TB。基于TeraSort基准测试的模型。 一个三行的Map函数从每行文本中提取出10字节的排序键，并将这个键和原始文本行作为中间的键/值对输出。使用了一个内建的Identity函数作为Reduce操作符，这个函数把中间文件原封不动的输出。最终排序后的输出写入到一组双重复制的GFS文件中（即程序的输出是2TB的数据）。 M=15000，R=4000.分区函数内置了关于键分布的知识。在一般的排序程序中，我们会增加一个预处理的MapReduce操作，用来收集一些键的样本，然后利用这些样本的分布计算最终排序阶段的分割点(可以确保每个Reduce任务接收到大致相等的负载)。 shuffle阶段是发生在map之后，是把中间的文件传给reduce的这个过程叫shuffle 备份任务的影响 仅用了前文所提到的备份任务后，时间多了44% 机器失败的影响 故意在计算的几分钟后杀死了1746个工作进程中的200个，相较于正常执行时间，仅增加了5%的时间","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://gladiouszhang.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"分布式系统","slug":"分布式系统","permalink":"http://gladiouszhang.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"}]},{"title":"边缘计算中的移动管理（Mobility Management）","slug":"边缘计算中的移动管理（Mobility-Management）","date":"2024-08-20T17:03:28.000Z","updated":"2024-11-07T16:09:24.727Z","comments":true,"path":"2024/08/21/边缘计算中的移动管理（Mobility-Management）/","permalink":"http://gladiouszhang.github.io/2024/08/21/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E4%B8%AD%E7%9A%84%E7%A7%BB%E5%8A%A8%E7%AE%A1%E7%90%86%EF%BC%88Mobility-Management%EF%BC%89/","excerpt":"","text":"资源发现 一些算法 1. 基于目录的资源发现（Directory-Based Resource Discovery） 2. 基于代理的资源发现（Agent-Based Resource Discovery） 3. 基于P2P的资源发现（Peer-to-Peer Resource Discovery） 4. 基于广播的资源发现（Broadcast-Based Resource Discovery） 5. 基于AI/ML的资源发现（AI/ML-Based Resource Discovery） 6. 基于协作的资源发现（Collaborative Resource Discovery） 7. 基于物理位置的资源发现（Location-Based Resource Discovery） 文献综述 不同类型的分布式系统 ~ 网格计算环境（稀疏） ~ P2P计算系统（点对点） ~ 集群计算（集中） 主要问题 主要的方法 一些相关的论文 ~ 一种在边缘网络中使用元数据复制进行资源发现的去中心化方法 - 问题背景 资源发现 资源发现是指在边缘计算环境中，移动设备需要及时找到可用的计算资源（如边缘服务器或云服务器）来执行任务。这包括识别最接近且最适合的边缘节点，以及在动态网络环境中快速发现可用资源。这一过程涉及多个技术，如网络感知、位置感知和服务发现协议等。 一些算法 1. 基于目录的资源发现（Directory-Based Resource Discovery） 方法设计： 目录服务： 中央目录服务器或分布式目录服务用于维护所有边缘节点及其可用资源的索引。 查询机制： 移动设备通过查询目录服务获取可用资源的列表。目录服务会根据资源的负载、网络延迟等条件返回最优资源。 优点： 查询效率高，适合静态或半动态环境。 挑战： 中央目录可能成为瓶颈，分布式目录需要复杂的同步机制。 2. 基于代理的资源发现（Agent-Based Resource Discovery） 方法设计： 智能代理： 部署在边缘节点或设备上的智能代理会主动发现并推荐资源。代理可以使用本地缓存、学习历史任务数据，以优化资源选择。 分布式协调： 代理之间可以通过协商或竞标机制，共同决定资源的分配。协商机制可以基于效用函数或策略投标。 优点： 自适应能力强，适应动态变化的网络环境。 挑战： 代理间的通信开销和复杂性较高。 3. 基于P2P的资源发现（Peer-to-Peer Resource Discovery） 方法设计： 分布式哈希表（DHT）： 使用DHT来索引和检索资源，提供高效的查询路由。每个节点负责管理一部分资源索引。 随机游走： 资源发现可以通过随机游走策略，让查询请求在网络中随机传播，直到找到合适的资源。 优点： 高度分布式，适合大规模动态环境。 挑战： 查询延迟可能较高，且可能出现查找失败的情况。 4. 基于广播的资源发现（Broadcast-Based Resource Discovery） 方法设计： 洪泛搜索： 移动设备可以广播资源请求给所有邻近节点，所有收到请求的节点都会响应。 限制广播： 为减少网络流量，设计限次广播或逐层扩展广播（如时间生存值TTL）。 优点： 简单直接，适合小规模网络。 挑战： 网络开销大，容易造成广播风暴。 5. 基于AI/ML的资源发现（AI/ML-Based Resource Discovery） 方法设计： 预测模型： 通过机器学习模型预测未来资源需求和可用性，智能调度资源分配。 强化学习： 使用强化学习方法，设备和边缘节点可以不断学习和优化资源发现策略。 优点： 动态性和自适应性强，能够应对复杂环境。 挑战： 需要大量训练数据和计算资源，可能增加系统复杂性。 6. 基于协作的资源发现（Collaborative Resource Discovery） 方法设计： 合作式资源分享： 多个边缘节点合作分享和发现资源，通过合作机制，如任务分发或资源借用，提高资源利用率。 分布式调度： 协作式调度机制能够根据任务优先级、节点负载情况动态调整资源发现策略。 优点： 提高资源利用效率，减少单点瓶颈。 挑战： 协作机制的设计复杂，需要考虑公平性和资源共享的效率。 7. 基于物理位置的资源发现（Location-Based Resource Discovery） 方法设计： 地理距离优化： 根据设备与边缘节点的物理距离优先选择最近的节点，以降低网络延迟。 区域划分： 将区域划分为多个小区，每个小区内的资源通过区域内广播或P2P方式发现。 优点： 提高服务质量（QoS），减少延迟。 挑战： 需要精确的位置感知技术，并可能面临区域内资源不均衡的问题。 文献综述 A. R. Khan, S. Imtiaz and A. H. Farooqi, “A Survey of the Resource Discovery Techniques in the Distributed Computing Systems,” 2022 International Conference on IT and Industrial Technologies (ICIT), Chiniot, Pakistan, 2022, pp. 1-6, doi: 10.1109/ICIT56493.2022.9989068. keywords: {Computer architecture;Distributed computing;distributed computing;resource discovery;net-work structures}, 分布式计算系统中的资源发现技术综述 不同类型的分布式系统 网格计算环境（稀疏） 包含多个可用资源，这些资源通常位于偏远位置，这些资源在地理上作为一个单元工作。目标是为手头的工作发现最有效的资源。 Javad Zarrin, Rui L Aguiar and João Paulo Barraca, “Resource discovery for distributed computing systems: A comprehensive survey”, Journal of parallel and distributed computing, vol. 113, pp. 127-166, 2018. P2P计算系统（点对点） 旨在通过允许对等方之间的资源共享来增强分布式环境的可扩展性。 S Vimal and S Srivatsa, “A new cluster p2p file sharing system based on ipfs and block-chain technology”, Journal of Ambient Intelligence and Humanized Computing, pp. 1-7, 2019. 集群计算（集中） 主要考虑调度问题，而不是资源发现。 Huang Wenzhun, Wang Haoxiang, Zhang Yucheng and Zhang Shanwen, “A novel cluster computing technique based on signal clustering and analytic hierarchy model using hadoop”, Cluster Computing, vol. 22, pp. 13077-13084, 2019. 主要问题 可扩展性：随着计算资源的增长 ，发现算法必须保持其性能。 效率：最小化用户请求发现适当资源时的响应时间。 异构性：满足不同设备的需求。 可靠性：定期维护已发现的资源，以消除资源不一致。 主要的方法 手动方法 手动方法依赖于用户手动输入资源请求并选择合适的资源。该方法通常通过模块化的方式处理请求，先接收用户的资源请求，然后按资源与请求的匹配度排序，最后根据访问成本对资源进行分组。虽然这种方法简单直接，但容易出现服务质量问题，因为优化的资源列表是在实时计算的 Massimiliano Assante, Leonardo Candela, Donatella Castelli, Roberto Cirillo, Gianpaolo Coro, Luca Frosini, Lucio Lelii, Francesco Man-giacrapa, Valentina Marioli, Pasquale Pagano et al., “The gcube system: delivering virtual research environments as-a-service”, Future Generation Computer Systems, vol. 95, pp. 445-453, 2019. 基于树的方法 基于树的方法使用决策树或其他树形结构来组织和管理资源。这些方法通过定期更新节点的属性值，并按优化的顺序存储资源信息，从而快速找到符合用户条件的资源。树结构的优势在于其查找效率（如O(log n)），但在数据不平衡的情况下可能导致查找效率降低 感觉红黑树可以解决平衡问题，然后个人感觉这就是在手动方法上面加了一个存储的数据结构？ Mohammad Samadi Gharajeh, “A knowledge and intelligent-based strategy for resource discovery on iaas cloud systems”, Int. J. Grid Util. Comput., vol. 12, no. 2, pp. 205-221, 2021. 语义方法 语义方法利用语义网技术，通过构建领域特定的本体（Ontology）来实现资源发现。这些方法通过存储和管理节点的语义信息，来帮助找到相关领域的资源。然而，由于依赖领域知识，这些方法在可扩展性方面存在局限性 语义网技术是一种通过为信息赋予明确意义的技术，使机器能够理解和处理数据，而不仅仅是读取。它为数据提供了一个结构化的、标准化的表示形式，使得不同系统之间的数据可以相互理解和处理。 本体是在特定领域内定义的概念和关系的集合，简单来说，它为某一领域的概念提供了一种标准化的表达方式。例如，在医疗领域，“医生”、“病人”、“治疗”可能都是本体中的概念，而它们之间的关系则可以被清晰地定义出来。 Aolong Zhou, Kaijun Ren, Xiaoyong Li, Wen Zhang, Xiaoli Ren and Kefeng Deng, “Semantic-based discovery method for high-performance computing resources in cyber-physical systems”, Microprocessors and Microsystems, vol. 80, pp. 103328, 2021. 基于对象的方法 基于对象的方法采用面向对象的方式来组织节点和资源信息。资源以对象的形式存储，并根据对象之间的关系进行管理。这种方法在管理大规模节点时具有优势，但由于维护每个对象的元信息的复杂性，可能会导致系统不稳定。 边缘计算方法 边缘计算方法适用于物联网（IoT）等分布式网络环境，重点在于在边缘设备上发现和管理资源。这种方法可以结合其他方法（如基于树或语义的方法）来优化资源发现，特别适合在性能和服务质量要求较高的场景中应用。 Gyeongmin Lee, Bongjun Kim, Seungbin Song, Seonyeong Heo and Hanjun Kim, “Comflex: Composable and flexible resource management for the iot”, IEEE Internet of Things Journal, vol. 8, no. 22, pp. 16406-16417, 2020. 一些相关的论文 一种在边缘网络中使用元数据复制进行资源发现的去中心化方法 I. Murturi and S. Dustdar, “A Decentralized Approach for Resource Discovery using Metadata Replication in Edge Networks,” in IEEE Transactions on Services Computing, vol. 15, no. 5, pp. 2526-2537, 1 Sept.-Oct. 2022, doi: 10.1109/TSC.2021.3082305. 问题背景 忽视了任务与物联网资源之间的关联性（就是说分配的任务可能是该物联网设备不擅长的） 边缘设备和网络组织之间的通信被忽视（比如设备、边缘服务器、云服务器这些之间的通信或者网络拓扑结构） 思路 应指定边缘网络以去中心化和自动的方式处理发现资源的复杂性（架构上） 以P2P的方式连接边缘设备。一组边缘设备组成一个集群（cluster）;而多个相连的集群组成一个边缘网络，分别是一个边缘邻域（edge neighborhood）。还存在相应的系统协调器，用于组织发现资源的过程。建立在 Kademlia 协议之上，作为边缘设备之间的通信协议。Kademlia 是用于去中心化 P2P 计算机网络的分布式哈希表 （DHT）。当边缘设备更新其本地 DHT 时，这些更改会传播到所有其他设备，从而允许再次查询和操作它们。同样，有关当前集群协调员和全局协调员的信息也存储在 DHT 中。协调器是动态放置的，并在提供各种服务的最合适的边缘设备上运行，动态评估。 发现边缘段的可用资源（发现过程） 以自动方式在边缘设备之间交换有关可用资源的信息： i）在整个系统中共享资源 ii）边缘设备在本地执行复杂的查询 通过提供有关功能及其属性的某些核心信息来描述资源。这种类型的描述称为资源的元数据，在边缘设备之间复制并以分布式的方式存储。 根据每个边缘设备的资源偏好处理隐私方面，确保并非所有资源都在整个系统中公布 邻居集群是通过使用系统调用（即 traceroute 命令）来找到的，该命令估计与其他集群协调器的接近程度（即，使用跃点计数和延迟）。 场景 城市自然灾害，无人机配备多种计算能力和传感器。考虑三层云基础设施：云、雾、边缘。雾设备提供计算和长期存储功能。 每个簇都有一个协调器设备（即带有绿色圆圈）和一个全局协调器设备（即带有红色和绿色圆圈）。我们假设集群协调器充当超级对等体 [35] 。每个集群协调器都跟踪同一集群中的其他协调器和设备（即 IP 地址、端口）。同样，同一集群中的边缘设备相互存储信息，并始终了解其集群协调器和全局协调器。集群协调器可能对设备子集承担各种职责（即，监视、发现资源等）。全局协调器负责监控协调器，在集群之间交换资源描述，并在边缘云基础设施中编排边缘应用程序（即控制弹性、迁移任务等）。 在本文中，我们主要关注三个方面：i）在边缘邻域中组织边缘设备，ii）确定最适合放置全局和集群协调器的设备，以及iii）在异构和动态的边缘邻域上实现自动资源发现。 资源切换 资源切换是指当移动设备在不同的网络环境或物理位置间移动时，需要无缝地切换正在使用的边缘资源。例如，当设备从一个边缘节点移动到另一个节点的覆盖范围内时，需要确保计算任务的迁移不会影响用户体验。这包括数据迁移、会话保持以及计算任务的状态保持等技术。 一些算法 1. 基于信号强度的切换（Signal Strength-Based Handoff） 方法设计： 信号测量： 移动设备通过持续测量当前连接节点的信号强度。当信号强度低于阈值时，触发切换。 切换策略： 系统会搜索周围其他边缘节点的信号强度，并选择信号最强的节点进行切换。 优点： 简单直观，易于实现。 挑战： 容易产生频繁切换，特别是在信号强度波动较大的情况下。 2. 基于位置预测的切换（Location Prediction-Based Handoff） 方法设计： 位置跟踪： 使用GPS或其他定位技术跟踪设备的位置变化。 运动预测： 通过历史位置数据和运动模式预测设备的未来位置，从而提前确定可能的切换节点。 优点： 提前准备切换，减少服务中断。 挑战： 需要精确的运动预测算法，且在复杂环境下定位精度可能受限。 3. 基于负载均衡的切换（Load Balancing-Based Handoff） 方法设计： 负载监控： 持续监控当前边缘节点的计算和网络负载，当负载超过设定的阈值时，启动切换。 动态分配： 切换到负载较轻的节点，以保证服务质量（QoS）。 优点： 保证节点的高效利用，防止过载。 挑战： 可能引入额外的延迟，尤其是在负载波动较大时。 4. 基于延迟感知的切换（Latency-Aware Handoff） 方法设计： 延迟测量： 持续监测当前节点到设备之间的通信延迟。 切换决策： 当延迟超过某个阈值时，系统将设备切换到延迟较低的节点。 优点： 提高用户体验，适合对延迟敏感的应用（如视频流或在线游戏）。 挑战： 需要实时的延迟监测，并且在网络拥塞时可能难以找到更好的节点。 5. 基于上下文感知的切换（Context-Aware Handoff） 方法设计： 多参数感知： 结合多种上下文信息（如设备电量、用户行为、网络状况）来做出切换决策。 自适应切换： 根据不同的应用需求和用户偏好，动态调整切换策略。 优点： 更智能的切换决策，提高服务的个性化体验。 挑战： 系统复杂度高，需要处理和分析大量上下文信息。 6. 基于AI/ML的切换（AI/ML-Based Handoff） 方法设计： 机器学习模型： 通过训练模型来预测最优切换节点，学习不同环境下的最佳切换策略。 强化学习： 使用强化学习算法，设备和边缘节点可以在运行中不断优化切换策略。 优点： 适应复杂动态环境，能够自动调整切换策略。 挑战： 需要大量数据和计算资源，且训练过程可能较为复杂。 7. 基于多路径的切换（Multi-Path-Based Handoff） 方法设计： 多路径连接： 在设备同时保持多个边缘节点的连接，选择最佳路径传输数据。 切换时机： 当主路径的性能下降时，系统自动切换到次优路径，确保服务连续性。 优点： 提高了切换的可靠性和稳定性。 挑战： 资源开销较大，且管理多路径连接的复杂性较高。 相关论文 多用户异构密集蜂窝网络的高能效业务迁移 X. Zhou, S. Ge, T. Qiu, K. Li and M. Atiquzzaman, “Energy-Efficient Service Migration for Multi-User Heterogeneous Dense Cellular Networks,” in IEEE Transactions on Mobile Computing, vol. 22, no. 2, pp. 890-905, 1 Feb. 2023, doi: 10.1109/TMC.2021.3087198. 摘要 业务迁移作为一个优化问题，目的是在满足服务延迟要求的同时，同时考虑到不同用户之间的干扰，最大限度地降低平均能耗。 开发了一种基于 Lyapunov 和粒子群优化的高效节能在线算法，称为 EGO，可以在不预测用户轨迹的情况下解决原始问题。 方法设计 在每个基站设置三层结构： 基础层（Base layer）：这是最底层的，类似于操作系统，是每个边缘服务器上通用的部分。无论是哪种服务或用户，这一层都是一致的，负责提供基本的计算资源和环境支持。 应用层（Application layer）：这一层位于基础层之上，由多个用户共享。它包含了特定的服务应用程序，也就是运行在边缘服务器上的实际业务逻辑和功能。当不同用户请求相同的服务时，他们会共享同一个应用层。 实例层（Instance layer）：这是最上层，与具体的用户绑定，包含该用户的服务状态信息，比如请求历史、用户信息以及其他私密数据。每个用户的实例层都是独立的，用于保存用户的个性化数据。 如果目标边缘服务器中已经部署了应用层，则用户只需从上一个服务节点（相邻的 BS）迁移其实例层即可。否则，用户需要同时迁移应用层和实例层。 具体建模 这个公示代表，用户在某一时间槽只连接到一个基站： 这个$$x’$$是指的t时刻将要迁移的服务，感觉有点导数的那个意思，也即下一时刻的状态 这个是指t时刻n基站上的m服务，如果存在有人在申请（$$\\ge1$$），那么这个$$P_t(m,n)$$（Place服务的数量）就是1，如果一个都没申请，那么就是0. 用八元组来表示一个服务： $$ &lt;λ_m,γ_m,D_m,f_{m,u},θ^A_m,θ^I_{m,u},W_m,ω_m&gt; $$ 具体含义见上面的表格 以下三个公式分别对基站$$n$$上某个时刻迁移服务时的最大CPU频率、最大存储容量、最大信道带宽进行了约束，就是在任何一个时刻，迁移时的这三个值都不得超过最大值 $$ \\begin{equation*} \\sum \\limits {m=1}^M\\sum \\limits {u=1}^U f{m,u} x{m,t}^\\prime (u,n) \\leq F_n,\\forall t,n, \\end{equation*} $$ $$ \\begin{equation*} \\sum \\limits _{m=1}^M\\Bigg [\\sum \\limits _{u=1}^U \\theta {m,u}^I x{m,t}^\\prime (u,n) + \\theta _m^A P_t^\\prime (m,n)\\Bigg ] \\leq S_n,\\forall t,n,\\end{equation*} $$ $$ \\begin{equation*} \\sum \\limits {m=1}^M \\sum \\limits {u=1}^U W{m,u} x{m,t}^\\prime (u,n) \\leq W_n,\\forall t,n, \\end{equation*} $$ 传输速率: $$\\begin{equation*} R(a,b)=W\\log {2}\\left(1+\\frac{p{a} h d(a,b)^{-3}}{N_0}\\right) \\end{equation*}$$，其实我感觉这里面的符号都不太用看 传输延迟包含两部分，第一部分是用户将请求发送到其连接的基站（BS）的延迟。这部分的精确时间无法捕获，用常数$$C$$表示；第二部分是从用户连接的基站传到用户服务的基站（这里不太理解，连接的基站不就是服务的基站？还是说是切换后的这样的基站？实际上这里讨论的是，如果某个连接的基站上没有某项服务，那么他会通过路由将请求转发到有服务的基站上，所以这应该是不考虑应用迁移，只考虑路由转发的情况）传输延迟计算公式： $$ \\begin{equation*} l_{m,t}^{tra}(u) = \\frac{\\lambda _m}{ R(\\pi _{t,u}^c,\\pi _{m,t,u})} + C \\end{equation*} $$ 其中： $$ \\begin{equation*} \\pi _{t,u}^c=\\arg\\max \\limits {n} x{t}^c(u,n)\\end{equation*} $$ $$ \\begin{equation*} \\pi _{m,t,u}=\\arg \\max \\limits {n} x{m,t}(u,n)\\end{equation*} $$ 其实就是从t时刻用户连接的那个BS传到t时刻用户访问服务的BS 计算延迟： $$ \\begin{equation*} l_{m,t}^{com}(u) = \\frac{\\lambda m\\gamma m}{f{m,u}}\\end{equation*} $$ 如果是服务迁移，从一个基站$$n$$迁移到另一个基站$$n’$$，迁移延迟是 $$ \\begin{equation*} l{m,t}^{app}(n) = \\min \\bigg\\lbrace \\frac{\\theta m^A |P_t^\\prime (m,n)-P{t}(m,n)|}{P_t^\\prime (m,n^\\prime)R(n,n^\\prime)}|n^\\prime = 1,\\ldots,N\\bigg\\rbrace \\end{equation*} $$ 区块链 P. Lang, D. Tian, X. Duan, J. Zhou, Z. Sheng and V. C. M. Leung, “Blockchain-Based Cooperative Computation Offloading and Secure Handover in Vehicular Edge Computing Networks,” in IEEE Transactions on Intelligent Vehicles, vol. 8, no. 7, pp. 3839-3853, July 2023, doi: 10.1109/TIV.2023.3271367. 基于预测 P. Guan, Y. Li and A. Taherkordi, “A Prediction Based Resource Reservation Algorithm for Service Handover in Edge Computing,” 2023 IEEE 10th International Conference on Cyber Security and Cloud Computing (CSCloud)/2023 IEEE 9th International Conference on Edge Computing and Scalable Cloud (EdgeCom), Xiangtan, Hunan, China, 2023, pp. 330-335, doi: 10.1109/CSCloud-EdgeCom58631.2023.00063.","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://gladiouszhang.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"分布式系统","slug":"分布式系统","permalink":"http://gladiouszhang.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"name":"边缘计算","slug":"边缘计算","permalink":"http://gladiouszhang.github.io/tags/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/"}]},{"title":"边缘计算论文阅读","slug":"边缘计算论文阅读","date":"2024-08-13T17:48:59.000Z","updated":"2025-03-02T08:04:59.466Z","comments":true,"path":"2024/08/14/边缘计算论文阅读/","permalink":"http://gladiouszhang.github.io/2024/08/14/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"Energy Consumption and QoS-Aware Co-Offloading for Vehicular Edge Computing 论文背景 论文思路 实验部分 Deep Graph-based Reinforcement Learning for Joint Cruise Control and Task Offloading for Aerial Edge Internet-of-Things (EdgeIoT) 论文背景 论文思路 具体模型 Energy Consumption and QoS-Aware Co-Offloading for Vehicular Edge Computing 论文背景 该论文探究在满足QoS前提下，尽可能降低能量开销的边缘计算。因为如果只追求低时延，可能会存在资源被浪费（例如大量任务被卸载到边缘端，过度分配资源，也就是增加了能量开销），只需要满足QoS就行，在这个前提下，尽可能的降低能量开销，是本文的核心任务。 论文思路 论文的目的是求出卸载率$\\lambda_n$（卸载多少）和RES的计算资源分配情况（往哪卸载）。在本文中，首先进行建模 然后对这个建好的模型进行求解。求解的过程中使用贝叶斯优化算法。先确定几个采样点，然后基于采集函数，在采集函数的最大值点设立新的采集点，以此类推，来拟合函数，找到近似的最大值点。 探索（exploration）是指选择代理模型预测不确定性较高的点，这些点可能尚未被充分评估。 利用（exploitation）是指优先选择那些已经被评估并且表现良好的区域，以期获得更好的结果。 提出了一个评价模型，是基于QoS和能量二元评价模型，返回值属于0-1： （感觉baseline就是自己提出的一种极端情况，不一定和别人的论文进行对比） 随着高维搜索空间的增长，BO变得缓慢。提出一种调优机制来收紧采样过程中的搜索空间： 在保持任务卸载比例不变的情况下，调整资源分配以满足任务的QoS约束。只要调整后的QoS仍然满足，调整是可以接受的。满足的适当减少资源，不满足的适当增加资源。 实验部分 我感觉就是假设了一些参数，然后对这些参数进行数值分析。 实验时选择一些已有算法进行对比（怎么选择？） 对比两个方面： 对比不同计算卸载模型的时延和能耗（分配得更合理） 对比采用算法的收敛速度（使用的方法更快） Deep Graph-based Reinforcement Learning for Joint Cruise Control and Task Offloading for Aerial Edge Internet-of-Things (EdgeIoT) 论文背景 背景：无人机作为移动边缘服务器，处理地面物联网设备的任务。 存在的问题：当无人机调度一个物联网设备卸载其计算任务时，在其他未被选中的设备上缓存的任务可能会过期而不得不取消。 提出一种优化方案，在物联网设备的计算能力和电池预算以及无人机的速度限制下，最大化卸载到无人机的任务。 求解这个方案的问题：优化包含较大的解空间，而无人机的瞬时网络状态是未知的。 论文思路 在物联网设备的计算能力和电池预算以及无人机的速度限制下，以卸载到无人机的计算任务数量最大化为目标，建立优化模型。所以优化目标其实是无人机的速度、方向和物联网设备上的任务调度情况。 提出了一种新的基于深度图的强化学习框架。开发了一种优势演员-评论家( A2C )结构，用于训练无人机在物联网设备的飞行速度、航向和卸载时间表方面的实时连续动作。 假设你有一群朋友，每个人之间都有各种关系，比如谁是好朋友，谁经常一起出去玩，谁在社交媒体上互相关注等。你可以把每个人看作一个“节点”，而这些朋友之间的关系可以看作是“边”。如果我们把这群朋友及其关系画出来，你就得到了一个“图”。 深度图（Deep Graph） 是用来处理这种“图”的一种计算方法。它不仅考虑了直接的关系（比如你和某个朋友的关系），还考虑了间接的关系（比如你朋友的朋友可能也会影响你）。通过使用深度学习的方法（如图神经网络），深度图可以从这种复杂的关系网中提取出有用的信息，比如谁在这群朋友中最有影响力，或者预测谁将成为好朋友。 想象一个游戏中的AI角色（演员），它负责在游戏世界中移动、攻击敌人、或收集资源。每次它做出一个动作（如移动到特定位置），评论家（Critic）会评估这个动作的结果，给出这个动作相对于当前状态下的其他可能动作的好坏程度（优势）。如果角色选择了一个带来高分数的动作，评论家会告诉演员“这个选择很好”，演员就会增加在类似情况下选择这个动作的概率。反之，如果动作结果不好，评论家会告诉演员“这不是一个好选择”，演员就会减少选择该动作的概率。通过这种方式，AI角色逐渐学会在不同的游戏状态下做出最佳的决策。 本文提出的GNN - A2C中开发了一个长短期记忆( long short-term memory，LSTM )模型，基于GNN中提取的特征来预测物联网设备上的时变无人机地面信道和任务生成。 具体模型 暂存一下符号的意思","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://gladiouszhang.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"分布式系统","slug":"分布式系统","permalink":"http://gladiouszhang.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"name":"边缘计算","slug":"边缘计算","permalink":"http://gladiouszhang.github.io/tags/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/"}]},{"title":"k8s实现pod内部的webshell","slug":"k8s实现pod内部的webshell","date":"2024-08-13T07:58:27.000Z","updated":"2024-08-13T16:32:58.000Z","comments":true,"path":"2024/08/13/k8s实现pod内部的webshell/","permalink":"http://gladiouszhang.github.io/2024/08/13/k8s%E5%AE%9E%E7%8E%B0pod%E5%86%85%E9%83%A8%E7%9A%84webshell/","excerpt":"","text":"背景介绍 代码介绍 handleConnections 背景介绍 这是实习的时候，公司让我开发的一个功能，主要希望实现的是前端与k8s中的pod的webshell功能，并且包含tab代码补全的功能。基于https://github.com/GanonYou/k8s-webshell-gin的代码来实现的。但是实现流程不一样：源代码是自己暴露出ws接口，等待前端连接），我的代码是集群先和后端建立ws，然后等待前端连接后端，然后前端先把消息传到后端，后端经过鉴权再转发给集群。 在本文档里，大致解释一下集群上的webshell（相当于是后端）的相关代码。 代码介绍 handleConnections 12345678910111213sshReq = ClientSet.CoreV1().RESTClient().Post(). Resource(&quot;pods&quot;). Name(pod). Namespace(namespace). SubResource(&quot;exec&quot;). VersionedParams(&amp;v1.PodExecOptions&#123; Container: container, Command: []string&#123;&quot;bash&quot;&#125;, Stdin: true, Stdout: true, Stderr: true, TTY: true, &#125;, scheme.ParameterCodec) 以上只是用于创建一个请求，还未发送。 ClientSet是一个指向 kubernetes.Clientset 类型的实例的指针，CoreV1提供了对 Kubernetes Core API 组，例如 Pods、Nodes、Services 等资源的访问，RESTClient()返回一个 rest.Interface 对象，允许直接使用 REST API 请求而不通过高层次的抽象。这个对象提供了更底层的 API 操作。最后，Post()用于构造一个 HTTP POST 请求。这个请求会用来与 Kubernetes API 交互，通常用于创建或更新资源。 SubResource(&quot;exec&quot;) 表示我们要操作的是 Pod 的 exec 子资源，这通常用于执行命令。即，我们希望在指定的 Pod 内执行某个命令。 VersionedParams()用于设置请求的参数，并且按照 API 版本对这些参数进行编码。 v1.PodExecOptions中： Container: 要执行命令的容器名。 Command: 要在容器中执行的命令数组。这里是 []string&#123;&quot;bash&quot;&#125;，表示在容器中启动一个 Bash shell。 Stdin, Stdout, Stderr: 这些布尔值表示是否需要连接标准输入、标准输出和标准错误。 TTY: 布尔值，表示是否需要终端 1234// 创建到容器的连接 if executor, err = remotecommand.NewSPDYExecutor(restConf, &quot;POST&quot;, sshReq.URL()); err != nil &#123; goto END &#125; 初始化一个 remotecommand.Executor 对象，以便能够通过 Kubernetes API 执行命令。创建 executor 的过程涉及配置 API 连接、指定 HTTP 方法（POST）以及构造执行请求的 URL。 sshReq.URL(): sshReq 是之前构建的 *rest.Request 对象，包含了 Kubernetes API 的请求信息。 sshReq.URL() 返回一个 *url.URL 对象，表示请求的完整 URL。这个 URL 指向 Kubernetes API 的 exec 子资源，用于执行命令。 例如，这个 URL 可能类似于 https://kubernetes/api/v1/namespaces/default/pods/my-pod/exec?stdin=true&amp;stdout=true&amp;stderr=true。 123456789101112handler = &amp;streamHandler&#123;wsConn: wsConn&#125;ctx = context.Background()if err = executor.StreamWithContext(ctx, remotecommand.StreamOptions&#123; Stdin: handler, Stdout: handler, Stderr: handler, // TerminalSizeQueue: handler, Tty: true,&#125;); err != nil &#123; goto END&#125; 将websocket直接连接到容器内的Stdin等。其实我修改后可以不用streamHandler，直接给我们的websocket加上io.read和write的接口就行，但是现在还没改。","categories":[],"tags":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://gladiouszhang.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"name":"实习项目","slug":"实习项目","permalink":"http://gladiouszhang.github.io/tags/%E5%AE%9E%E4%B9%A0%E9%A1%B9%E7%9B%AE/"}]},{"title":"边缘计算综述","slug":"边缘计算综述","date":"2024-08-02T14:39:15.000Z","updated":"2024-08-16T06:56:24.000Z","comments":true,"path":"2024/08/02/边缘计算综述/","permalink":"http://gladiouszhang.github.io/2024/08/02/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E7%BB%BC%E8%BF%B0/","excerpt":"","text":"研究热点 关键技术 计算卸载 移动管理 流量卸载 缓存加速 网络控制 数据安全和隐私保护 四个挑战 研究体系 K. Cao, Y. Liu, G. Meng和Q. Sun, 《An Overview on Edge Computing Research》, IEEE Access, 卷 8, 页 85714–85728, 2020, doi: 10.1109/ACCESS.2020.2991734. 研究热点 关键技术 计算卸载 资源受限设备将资源密集型计算从移动设备上部分或全部地移植到资源富集的临近设备： 卸载决策 如何卸载计算任务，卸载多少，卸载些啥。 分为三个部分：编码阶段决定要卸载什么，系统阶段监控变量（带宽、数据大小等），决策引擎决定是否卸载 决策结果分为三种情况：本地执行（不卸载）、部分卸载、全部卸载。 决策的目标可以被分为（分别满足）：减小延迟、降低能量开销、平衡能量开销和延迟 资源分配 往哪卸载。比如有些部分不能拆分，或者拆分后有联系的，就必须放在同样的MEC(Mobile Edge Computing)服务器。 通常分配节点被分为单点分配和多点分配。 移动管理 一个边缘计算节点只服务于其周围的人。 主要问题是资源发现和资源切换。 资源发现 用户在移动中快速发现周围的可用资源，并选择最合适的资源。 资源切换 当用户移动时，移动应用所使用的计算资源可能会在多个设备之间进行切换，同时会改变服务程序的工作站点来保证服务连续性。 流量卸载 将满足特定卸载规则的流量卸载到移动边缘网络(即一个局部特定的网络,可以是内部网,也可以是因特网)，以节省回程带宽，减少延迟，并促进其他MEC服务的扩展。 假设你在一个繁忙的购物中心使用手机，正在观看一个高清的实时视频。传统情况下，所有的数据请求都需要通过蜂窝网络的核心网传输，然后通过互联网访问视频内容服务器。由于购物中心的人流量大，蜂窝网络的核心网可能会承载大量的流量，导致网络拥塞、延迟增加。 为了优化这个场景，网络运营商部署了一个MEC（移动边缘计算）节点，它包含视频内容的本地缓存，并支持流量卸载。当你在购物中心观看视频时，视频流量会被卸载到这个MEC节点。也就是说，视频数据直接从购物中心附近的MEC节点获取，而不是经过蜂窝网络的核心网。这不仅减少了核心网的负担，还显著降低了延迟，提高了视频流的质量。 和计算卸载的区别是，计算卸载是把本地任务卸载到边缘端服务器，流量卸载是将流量负担较大的线路转移。计算卸载重点在于“任务执行”的转移，流量卸载重点在于“数据内容传输”的转移。 缓存加速 内容缓存到移动网络边缘后，用户可以就近获取内容，从而避免了内容的重复传输，缓解了回程网络和核心网的压力。 缓存加速本质上是一种特定的流量卸载策略，其中的重点是对内容进行本地化存储，以减少传输需求。 流量卸载的范围更广，它不仅包括缓存加速，还可能包括其他形式的流量转移或重新路由，目的是减轻核心网络的整体负担。 网络控制 这一块论文没咋讲，gpt如是说： 网络控制是指在网络基础设施中管理和调度数据流、资源分配以及通信行为的过程和机制。它涉及如何控制网络中的流量、优化性能、确保安全性和稳定性，并响应不同的网络需求。网络控制在整个网络中扮演着关键角色，特别是在大型、复杂的网络环境中，比如在边缘网络和云计算环境中。 数据安全和隐私保护 边缘计算的分布式结构增加了攻击向量的维度。边缘计算客户端越智能，越容易受到恶意软件的感染和安全漏洞的攻击。网络边缘高度动态的环境也使得网络更加脆弱。 四个挑战 轻量级的数据加密和在多个授权团体基础上的细粒度数据分享： 设计针对多个授权中心的数据加密方法，考虑复杂度。 分布式计算环境下的多源异构数据传播控制与安全管理： 用户或数据拥有者希望能够利用有效的信息发布控制和访问控制机制，实现数据的分发、搜索、访问以及对数据授权范围的控制。 边缘计算大规模互联服务与资源受限终端之间的安全挑战 面向物联网的多样化服务和边缘计算模式对高效隐私保护的新要求 研究体系 数据安全 数据的加密及对其的安全操作。思路是将其他计算范式（如云计算、雾计算等）安全解决方案移植过来，并将计算架构并行化，最终实现一个轻量级的、分布式的数据安全防护系统。 数据加密和安全数据分享 身份认证 隐私保护 访问控制","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://gladiouszhang.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"分布式系统","slug":"分布式系统","permalink":"http://gladiouszhang.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"name":"边缘计算","slug":"边缘计算","permalink":"http://gladiouszhang.github.io/tags/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/"}]},{"title":"k8s集群minio作pvc挂载介绍及示例","slug":"k8s集群minio作pvc挂载","date":"2024-07-31T16:33:26.000Z","updated":"2024-08-11T09:07:36.000Z","comments":true,"path":"2024/08/01/k8s集群minio作pvc挂载/","permalink":"http://gladiouszhang.github.io/2024/08/01/k8s%E9%9B%86%E7%BE%A4minio%E4%BD%9Cpvc%E6%8C%82%E8%BD%BD/","excerpt":"","text":"MinIO介绍 PVC概念（Persistent Volume Claim） MinIO与PVC的结合 配置步骤 创建相关存储服务 1. 创建Persistent Volume (PV) 和 Persistent Volume Claim (PVC) MinIO介绍 参考：https://www.cnblogs.com/yuxl01/p/16226701.html MinIO 是一个高性能的对象存储系统，常用于存储大量非结构化数据，例如图片、视频、备份文件等。它以分布式方式运行，确保数据的高可用性和可靠性。 PVC概念（Persistent Volume Claim） 在Kubernetes中，Persistent Volume (PV) 是集群中由管理员提供的一块存储资源，而Persistent Volume Claim (PVC) 则是用户对存储资源的请求。PVC允许用户动态地申请存储资源，并将其挂载到Pod中，以便持久存储数据。 MinIO与PVC的结合 将MinIO作为PVC挂载使用，可以使应用程序方便地使用MinIO提供的存储资源，并且通过Kubernetes的调度和管理功能，保证存储服务的高可用性和可扩展性。 大致流程如下： 用户 &lt;–&gt; MinIO：用户上传或下载数据。 MinIO &lt;–&gt; PVC：MinIO的部署配置请求存储资源（PVC）。 PVC &lt;–&gt; PV：Kubernetes将PVC绑定到合适的PV，提供实际的存储资源。 PV：实际存储数据的位置。 配置步骤 写一个简单的demo，演示一下上传一条记录到minio的过程 创建相关存储服务 1. 创建Persistent Volume (PV) 和 Persistent Volume Claim (PVC) 创建一个PV配置文件 minio-pv.yaml，给这个PV分配10G空间 12345678910111213apiVersion: v1kind: PersistentVolumemetadata: name: minio-pvspec: capacity: storage: 100Mi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Retain storageClassName: manual hostPath: path: &quot;/mnt/data&quot; 创建一个PVC配置文件 minio-pvc.yaml： 1234567891011apiVersion: v1kind: PersistentVolumeClaimmetadata: name: minio-pvcspec: accessModes: - ReadWriteOnce resources: requests: storage: 100Mi storageClassName: manual 2. 部署MinIO 创建一个MinIO部署文件 minio-deployment.yaml，使用前面创建的pvc 123456789101112131415161718192021222324252627282930313233343536apiVersion: apps/v1kind: Deploymentmetadata: name: minio-deployment labels: app: miniospec: replicas: 1 selector: matchLabels: app: minio template: metadata: labels: app: minio spec: containers: - name: minio image: minio/minio:latest args: - server - /data ports: - containerPort: 9000 env: - name: MINIO_ACCESS_KEY value: &quot;minioadmin&quot; - name: MINIO_SECRET_KEY value: &quot;minioadmin&quot; volumeMounts: - name: minio-storage mountPath: /data volumes: - name: minio-storage persistentVolumeClaim: claimName: minio-pvc 创建一个MinIO服务文件 minio-service.yaml，用于提供一种访问方式 12345678910111213apiVersion: v1kind: Servicemetadata: name: minio-service labels: app: miniospec: type: LoadBalancer ports: - port: 9000 targetPort: 9000 selector: app: minio 踩坑：由于在本地环境下，LoadBalancer 类型的服务不会自动获得一个外部 IP 地址。即： 所以改为NodePort类型的服务。 NodePort 是一种服务类型，它在所有集群节点的一个静态端口（NodePort）上为服务开放一个端口。这意味着你可以通过任何节点的 IP 地址加上这个端口来访问服务。 修改后的yaml文件为： 1234567891011121314apiVersion: v1kind: Servicemetadata: name: minio-service labels: app: miniospec: type: NodePort ports: - port: 9000 targetPort: 9000 nodePort: 31909 selector: app: minio 3. 应用配置文件 使用 kubectl 命令行工具应用这些配置文件： 1234kubectl apply -f minio-pv.yamlkubectl apply -f minio-pvc.yamlkubectl apply -f minio-deployment.yamlkubectl apply -f minio-service.yaml 编写上传记录的Go程序 1. 安装MinIO的Go SDK 首先安装MinIO的Go SDK： 1go get github.com/minio/minio-go/v7 2. 编写上传记录的Go程序 编写一个简单的Go程序来上传一条记录： 这里有一个桶的概念。桶（Bucket）是用来组织和管理数据的主要容器。每个桶可以包含任意数量的对象（文件），可以把桶想象成一个顶级文件夹，它用来存储数据对象。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport ( &quot;bytes&quot; &quot;context&quot; &quot;fmt&quot; &quot;log&quot; &quot;github.com/minio/minio-go/v7&quot; &quot;github.com/minio/minio-go/v7/pkg/credentials&quot;)func main() &#123; // 初始化MinIO客户端 minioClient, err := minio.New(&quot;localhost:9000&quot;, &amp;minio.Options&#123; Creds: credentials.NewStaticV4(&quot;minioadmin&quot;, &quot;minioadmin&quot;, &quot;&quot;), Secure: false, &#125;) if err != nil &#123; log.Fatalln(err) &#125; // 创建一个桶（bucket） bucketName := &quot;mybucket&quot; location := &quot;china&quot; err = minioClient.MakeBucket(context.Background(), bucketName, minio.MakeBucketOptions&#123;Region: location&#125;) if err != nil &#123; // 检查桶是否已经存在 exists, errBucketExists := minioClient.BucketExists(context.Background(), bucketName) if errBucketExists == nil &amp;&amp; exists &#123; fmt.Printf(&quot;Bucket &#x27;%s&#x27; already exists.\\n&quot;, bucketName) &#125; else &#123; log.Fatalln(err) &#125; &#125; else &#123; fmt.Printf(&quot;Bucket &#x27;%s&#x27; created successfully.\\n&quot;, bucketName) &#125; // 上传一条记录 recordContent := &quot;This is a test record.&quot; recordName := &quot;test_record.txt&quot; _, err = minioClient.PutObject(context.Background(), bucketName, recordName, bytes.NewReader([]byte(recordContent)), int64(len(recordContent)), minio.PutObjectOptions&#123;ContentType: &quot;text/plain&quot;&#125;) if err != nil &#123; log.Fatalln(err) &#125; fmt.Println(&quot;Record uploaded successfully.&quot;)&#125; 3. 运行程序 将上述Go代码保存为 main.go，然后运行它： 1go run main.go 尝试删、改、查 上传对象 直接拆出来 123456789101112func uploadObject(minioClient minio.Client, bucketName string) &#123; // 上传一条记录 recordContent := &quot;This is a test record.&quot; recordName := &quot;test_record.txt&quot; _, err := minioClient.PutObject(context.Background(), bucketName, recordName, bytes.NewReader([]byte(recordContent)), int64(len(recordContent)), minio.PutObjectOptions&#123;ContentType: &quot;text/plain&quot;&#125;) if err != nil &#123; log.Fatalln(err) &#125; fmt.Println(&quot;Record uploaded successfully.&quot;)&#125; 删除对象 删除一个已经存在的对象： 12345678func removeObject(minioClient *minio.Client, bucketName, objectName string) &#123; ctx := context.Background() err := minioClient.RemoveObject(ctx, bucketName, objectName, minio.RemoveObjectOptions&#123;&#125;) if err != nil &#123; log.Fatalln(err) &#125; log.Printf(&quot;Successfully deleted %s\\n&quot;, objectName)&#125; 上传（修改）对象 上传一个新的对象或覆盖一个已经存在的对象可以视为“修改”操作： 1234567891011import &quot;bytes&quot;func modifyObject(minioClient *minio.Client, bucketName, objectName, objectContent string) &#123; ctx := context.Background() reader := bytes.NewReader([]byte(objectContent)) _, err := minioClient.PutObject(ctx, bucketName, objectName, reader, int64(len(objectContent)), minio.PutObjectOptions&#123;ContentType: &quot;text/plain&quot;&#125;) if err != nil &#123; log.Fatalln(err) &#125; log.Printf(&quot;Successfully uploaded %s\\n&quot;, objectName)&#125; 检索（查）对象 检索（查）操作包括列出所有对象名称和内容 1234567891011121314151617181920212223242526272829303132func getObjectContent(minioClient *minio.Client, bucketName, objectName string) &#123; ctx := context.Background() // 使用 GetObject 获取对象 object, err := minioClient.GetObject(ctx, bucketName, objectName, minio.GetObjectOptions&#123;&#125;) if err != nil &#123; log.Fatalln(err) &#125; defer object.Close() // 读取对象的内容 data, err := io.ReadAll(object) if err != nil &#123; log.Fatalln(err) &#125; // 输出对象的内容 log.Printf(&quot;Content of %s: %s\\n&quot;, objectName, string(data))&#125;func listObjectsAndContents(minioClient *minio.Client, bucketName string) &#123; ctx := context.Background() objectCh := minioClient.ListObjects(ctx, bucketName, minio.ListObjectsOptions&#123;&#125;) for object := range objectCh &#123; if object.Err != nil &#123; log.Fatalln(object.Err) &#125; log.Printf(&quot;Found %s\\n&quot;, object.Key) getObjectContent(minioClient, bucketName, object.Key) &#125;&#125; 踩坑 目前最大的问题是dockerhub访问不了，有解决方式，包括挂代理、使用cloudflare托管等，我在这里找到了一个暂且还能使用的镜像源https://docker.1panel.live 数据安全 数据加密 服务器端上传加密，将对象通过自定义的密钥加密并上传至服务器，以保护数据安全。使用 encrypt.NewSSEC 函数来创建一个服务器端加密（SSE）对象，该函数接收一个密钥 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package mainimport ( &quot;context&quot; &quot;log&quot; &quot;github.com/minio/minio-go/v7&quot; &quot;github.com/minio/minio-go/v7/pkg/credentials&quot; &quot;github.com/minio/minio-go/v7/pkg/encrypt&quot;)func main() &#123; // 连接到Minio服务器 endpoint := &quot;play.min.io&quot; accessKeyID := &quot;YOUR-ACCESSKEYID&quot; secretAccessKey := &quot;YOUR-SECRETACCESSKEY&quot; useSSL := true // 初始化minio client对象 minioClient, err := minio.New(endpoint, &amp;minio.Options&#123; Creds: credentials.NewStaticV4(accessKeyID, secretAccessKey, &quot;&quot;), Secure: useSSL, &#125;) if err != nil &#123; log.Fatalln(err) &#125; // 创建一个加密的存储桶 bucketName := &quot;encrypted-bucket&quot; location := &quot;us-east-1&quot; err = minioClient.MakeBucket(context.Background(), bucketName, minio.MakeBucketOptions&#123;Region: location&#125;) if err != nil &#123; // 检查是否已经存在 exists, errBucketExists := minioClient.BucketExists(context.Background(), bucketName) if errBucketExists == nil &amp;&amp; exists &#123; log.Printf(&quot;Bucket %s already exists\\n&quot;, bucketName) &#125; else &#123; log.Fatalln(err) &#125; &#125; else &#123; log.Printf(&quot;Bucket %s created successfully\\n&quot;, bucketName) &#125; // 设置加密密钥 encryptionKey := &quot;MY-ENCRYPTION-KEY&quot; sse := encrypt.NewSSEC([]byte(encryptionKey)) // 上传文件并加密 objectName := &quot;encrypted-file.txt&quot; filePath := &quot;file.txt&quot; contentType := &quot;application/text&quot; uploadInfo, err := minioClient.FPutObject(context.Background(), bucketName, objectName, filePath, minio.PutObjectOptions&#123; ContentType: contentType, ServerSideEncryption: sse, &#125;) if err != nil &#123; log.Fatalln(err) &#125; log.Printf(&quot;Successfully uploaded %s of size %d\\n&quot;, objectName, uploadInfo.Size)&#125; 创建了一个名为“encrypted-bucket”的加密存储桶。然后，设置了一个自定义的加密密钥，并使用该密钥对文件进行加密上传。上传到Minio服务器的文件将以加密形式存储，保护了数据的机密性。 访问控制 除了数据加密，Minio还提供了访问控制功能，可以帮助用户控制对存储桶和对象的访问权限。通过设置适当的访问策略，用户可以限制谁可以读取和写入存储桶中的对象，从而提高数据的安全性。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;log&quot; &quot;github.com/minio/minio-go/v7&quot; &quot;github.com/minio/minio-go/v7/pkg/credentials&quot;)func main() &#123; // 连接到Minio服务器 endpoint := &quot;play.min.io&quot; accessKeyID := &quot;YOUR-ACCESSKEYID&quot; secretAccessKey := &quot;YOUR-SECRETACCESSKEY&quot; useSSL := true// 初始化minio client对象minioClient, err := minio.New(endpoint, &amp;minio.Options&#123; Creds: credentials.NewStaticV4(accessKeyID, secretAccessKey, &quot;&quot;), Secure: useSSL,&#125;)if err != nil &#123; log.Fatalln(err)&#125;// 设置存储桶的访问策略bucketName := &quot;encrypted-bucket&quot;username := &quot;specific-user&quot; // 替换为你想允许写入的特定用户的用户名policy := `&#123; &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ &#123; &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: &#123;&quot;AWS&quot;: &quot;arn:aws:iam::` + username + `&quot;&#125;, &quot;Action&quot;: [ &quot;s3:PutObject&quot;, &quot;s3:DeleteObject&quot; ], &quot;Resource&quot;: &quot;arn:aws:s3:::` + bucketName + `/*&quot; &#125;, &#123; &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: &quot;*&quot;, &quot;Action&quot;: &quot;s3:GetObject&quot;, &quot;Resource&quot;: &quot;arn:aws:s3:::` + bucketName + `/*&quot; &#125; ]&#125;`err = minioClient.SetBucketPolicy(context.Background(), bucketName, policy)if err != nil &#123; log.Fatalln(err)&#125;fmt.Println(&quot;Bucket policy set successfully.&quot;)&#125; 创建一个策略文档，其中包含两个声明： 第一个声明：允许特定用户（通过其ARN表示）进行写操作（包括PutObject和DeleteObject）。 第二个声明：允许所有用户进行读操作（GetObject）。 SSL/TLS支持 Minio还支持通过SSL/TLS对数据进行安全传输。通过启用SSL/TLS，所有传输的数据都将进行加密，从而防止中间人攻击和数据泄露。 123456789101112131415161718192021222324252627package mainimport ( &quot;log&quot; &quot;github.com/minio/minio-go/v7&quot; &quot;github.com/minio/minio-go/v7/pkg/credentials&quot;)func main() &#123; // 连接到启用了SSL/TLS的Minio服务器 endpoint := &quot;play.min.io&quot; accessKeyID := &quot;YOUR-ACCESSKEYID&quot; secretAccessKey := &quot;YOUR-SECRETACCESSKEY&quot; useSSL := true// 初始化minio client对象minioClient, err := minio.New(endpoint, &amp;minio.Options&#123; Creds: credentials.NewStaticV4(accessKeyID, secretAccessKey, &quot;&quot;), Secure: useSSL,&#125;)if err != nil &#123; log.Fatalln(err)&#125;log.Println(&quot;Successfully connected to Minio server.&quot;)&#125; 版本控制 通过启用版本控制，Minio可以保存对象的多个版本，以防止数据丢失和意外删除。 1234567891011121314151617181920212223242526272829303132333435package mainimport ( &quot;context&quot; &quot;log&quot; &quot;github.com/minio/minio-go/v7&quot; &quot;github.com/minio/minio-go/v7/pkg/credentials&quot;)func main() &#123; // 连接到Minio服务器 endpoint := &quot;play.min.io&quot; accessKeyID := &quot;YOUR-ACCESSKEYID&quot; secretAccessKey := &quot;YOUR-SECRETACCESSKEY&quot; useSSL := true// 初始化minio client对象minioClient, err := minio.New(endpoint, &amp;minio.Options&#123; Creds: credentials.NewStaticV4(accessKeyID, secretAccessKey, &quot;&quot;), Secure: useSSL,&#125;)if err != nil &#123; log.Fatalln(err)&#125;// 启用版本控制bucketName := &quot;my-bucket&quot;err = minioClient.EnableVersioning(context.Background(), bucketName)if err != nil &#123; log.Fatalln(err)&#125;log.Println(&quot;Versioning enabled successfully.&quot;)&#125; 锁定措施 通过启用对象锁定，Minio可以保护数据免受意外删除或覆盖，并实现数据保留和合规性要求。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package mainimport ( &quot;context&quot; &quot;log&quot; &quot;time&quot; &quot;github.com/minio/minio-go/v7&quot; &quot;github.com/minio/minio-go/v7/pkg/credentials&quot;)func main() &#123; // 连接到Minio服务器 endpoint := &quot;play.min.io&quot; accessKeyID := &quot;YOUR-ACCESSKEYID&quot; secretAccessKey := &quot;YOUR-SECRETACCESSKEY&quot; useSSL := true// 初始化minio client对象minioClient, err := minio.New(endpoint, &amp;minio.Options&#123; Creds: credentials.NewStaticV4(accessKeyID, secretAccessKey, &quot;&quot;), Secure: useSSL,&#125;)if err != nil &#123; log.Fatalln(err)&#125;// 启用对象锁定bucketName := &quot;my-lock-enabled-bucket&quot;err = minioClient.MakeBucket(context.Background(), bucketName, minio.MakeBucketOptions&#123;ObjectLocking: true&#125;)if err != nil &#123; log.Fatalln(err)&#125;log.Println(&quot;Bucket with object lock enabled created successfully.&quot;)// 上传带有锁定策略的对象objectName := &quot;my-object.txt&quot;filePath := &quot;path/to/your/file.txt&quot;contentType := &quot;application/text&quot;lockMode := minio.GovernanceretainUntilDate := time.Now().Add(24 * time.Hour) // 保留24小时uploadInfo, err := minioClient.PutObject(context.Background(), bucketName, objectName, filePath, -1, minio.PutObjectOptions&#123; ContentType: contentType, RetainUntilDate: retainUntilDate, Mode: lockMode,&#125;)if err != nil &#123; log.Fatalln(err)&#125;log.Printf(&quot;Successfully uploaded %s with lock mode %s until %v\\n&quot;, objectName, lockMode, retainUntilDate)&#125; 数据完整性检查 通过计算文件的哈希值并在上传和下载过程中进行验证，可以确保数据在传输过程中没有被损坏。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package mainimport ( &quot;context&quot; &quot;crypto/sha256&quot; &quot;fmt&quot; &quot;io&quot; &quot;log&quot; &quot;os&quot; &quot;github.com/minio/minio-go/v7&quot; &quot;github.com/minio/minio-go/v7/pkg/credentials&quot;)func main() &#123; // 连接到Minio服务器 endpoint := &quot;play.min.io&quot; accessKeyID := &quot;YOUR-ACCESSKEYID&quot; secretAccessKey := &quot;YOUR-SECRETACCESSKEY&quot; useSSL := true// 初始化minio client对象minioClient, err := minio.New(endpoint, &amp;minio.Options&#123; Creds: credentials.NewStaticV4(accessKeyID, secretAccessKey, &quot;&quot;), Secure: useSSL,&#125;)if err != nil &#123; log.Fatalln(err)&#125;// 上传文件并计算哈希值bucketName := &quot;my-bucket&quot;objectName := &quot;my-object.txt&quot;filePath := &quot;path/to/your/file.txt&quot;file, err := os.Open(filePath)if err != nil &#123; log.Fatalln(err)&#125;defer file.Close()hash := sha256.New()tee := io.TeeReader(file, hash)uploadInfo, err := minioClient.PutObject(context.Background(), bucketName, objectName, tee, -1, minio.PutObjectOptions&#123;&#125;)if err != nil &#123; log.Fatalln(err)&#125;log.Printf(&quot;Successfully uploaded %s of size %d\\n&quot;, objectName, uploadInfo.Size)log.Printf(&quot;SHA-256 hash: %x\\n&quot;, hash.Sum(nil))// 下载文件并验证哈希值downloadFilePath := &quot;path/to/your/downloaded_file.txt&quot;err = minioClient.FGetObject(context.Background(), bucketName, objectName, downloadFilePath, minio.GetObjectOptions&#123;&#125;)if err != nil &#123; log.Fatalln(err)&#125;downloadedFile, err := os.Open(downloadFilePath)if err != nil &#123; log.Fatalln(err)&#125;defer downloadedFile.Close()downloadHash := sha256.New()if _, err := io.Copy(downloadHash, downloadedFile); err != nil &#123; log.Fatalln(err)&#125;log.Printf(&quot;Downloaded file SHA-256 hash: %x\\n&quot;, downloadHash.Sum(nil))if hash.Sum(nil) == downloadHash.Sum(nil) &#123; log.Println(&quot;Data integrity verified successfully.&quot;)&#125; else &#123; log.Println(&quot;Data integrity verification failed.&quot;)&#125;&#125; 在上传文件时，通过io.TeeReader同时计算文件的SHA-256哈希值。 下载文件后，重新计算下载文件的SHA-256哈希值。 比较上传和下载文件的哈希值以验证数据的完整性。","categories":[],"tags":[{"name":"分布式系统","slug":"分布式系统","permalink":"http://gladiouszhang.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"name":"实习项目","slug":"实习项目","permalink":"http://gladiouszhang.github.io/tags/%E5%AE%9E%E4%B9%A0%E9%A1%B9%E7%9B%AE/"}]},{"title":"Java学习笔记——List, Set, Map","slug":"Java学习笔记——List-Set-Map","date":"2024-04-18T11:47:16.000Z","updated":"2024-08-11T10:06:26.000Z","comments":true,"path":"2024/04/18/Java学习笔记——List-Set-Map/","permalink":"http://gladiouszhang.github.io/2024/04/18/Java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94List-Set-Map/","excerpt":"","text":"List(包含ArrayList, Vector, LinkedList) ArrayList底层使用数组实现数据存储 ArrayList基本等同与Vector，但是Vector线程安全（因此ArrayList更快） ArrayList源码分析： 维护一个Object类型的数组elementData，如果使用无参构造器，初始化数组大小为0，第一次添加扩容为10，再次扩容是每次扩容1.5倍。如果使用指定大小的构造器，则直接初始化为指定大小，每次扩容1.5倍。elementData用transient修饰，表示该属性不会被序列化。 Vector底层也是elementData数组，多线程操作时使用Vector。无参构造时默认长度为10，满了以后每次增加2倍，如果指定大小，满后则直接扩容两倍（其实可以设置每次增长量，如果没有设置，就默认翻倍） LinkedList底层实现了双向链表和双端队列，没有实现同步，线程不安全。增删较多用LinkedList，改查较多用ArrayList Set(包含HashSet, LinkedHashSet) hashset底层是hashmap，hashmap底层是数组+链表+红黑树，hashmap初始化长度为16，数据到一定量(JAVA8中链表长度≥8，table大小≥64)后变成红黑树。如果链表到了8，table没到64，那么table扩容为2倍。此外，table中所有节点的数量到threshold(0.75乘以table长度，初始是16*0.75=12)时进行扩容，扩容也是扩为2倍。扩容的同时，原有的元素会被重新放置（因为数组大小改变）。 LinkedHashSet底层是一个LinkedHashMap，其底层维护了一个数组+双向链表，使用hashCode决定在table中的位置，双向链表维护插入顺序，使得元素看起来是按顺序插入的。相当于在HashTable（HashMap）的Node外面套了一层壳（Entry），加上了before和after字段。其目的就是为了维护顺序，并且减小查询开销（可以直接计算hash）。遍历时使用LinkedHashMap的head字段进行遍历。扩容等机制和HashMap相同。 Map(包含HashMap, LinkedHashMap, Hashtable, Priorities) HashMap在加入相同键时会发生替换，而替换时并不会改变modCount，modCount是一个用于记录HashMap结构修改次数（改变HashMap中映射数量或者修改内部结构）的变量。HashMap是线程不安全的。 Hashtable底层维护一个table数组，数组存储Hashtable$Entry对象，形成链表。初始化table大小11，threshold为大小乘以0.75(向下取整)。扩容机制:左移一位(乘以二)加一。Hashtable的效率比HashMap低。HashTable的键值都不能为空，是线程安全的 properties可以读取xx.properties文件，获取文件中的配置(举例:数据库) 如何选择 插入单列元素：Collection(List、Set) 允许重复：List 不用线程安全，效率高： 具有大量增删操作：LinkedList 具有大量改查操作：ArrayList 线程安全，效率低：Vector 不允许重复：Set 无序：HashSet（底层使用HashMap） 排序：TreeSet 按插入顺序：LinkedHashSet（底层使用LinkedHashMap） 插入双列元素：Map 无需线程安全： 无序：HashMap 排序：TreeMap 按插入顺序：LinkedHashMap 线程安全： 读取文件：Properties 其他：Hashtable","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://gladiouszhang.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"Java","slug":"Java","permalink":"http://gladiouszhang.github.io/tags/Java/"}]},{"title":"Java学习笔记——包装类","slug":"Java学习笔记——包装类","date":"2024-04-13T11:46:10.000Z","updated":"2024-07-31T11:46:50.000Z","comments":true,"path":"2024/04/13/Java学习笔记——包装类/","permalink":"http://gladiouszhang.github.io/2024/04/13/Java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%8C%85%E8%A3%85%E7%B1%BB/","excerpt":"","text":"装箱： 基本类型-&gt;包装类型。拆箱相反。jdk5及以后自动拆装箱。 手动装箱需要用到new Integer(n)或者Integer.valueOf(n)，手动拆箱需要integer.intValue()。自动拆装箱可以无视数据类型直接赋值，但底层实际上还是一样的。 Integer使用自动装箱（或手动装箱的valueOf方法）创建对象时，如果范围在-128-127范围内，返回的对象是同一个，不在范围内时底层new对象。","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://gladiouszhang.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"Java","slug":"Java","permalink":"http://gladiouszhang.github.io/tags/Java/"}]},{"title":"Java学习笔记——异常","slug":"Java学习笔记——异常","date":"2024-04-12T11:44:46.000Z","updated":"2024-07-31T11:45:50.000Z","comments":true,"path":"2024/04/12/Java学习笔记——异常/","permalink":"http://gladiouszhang.github.io/2024/04/12/Java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%BC%82%E5%B8%B8/","excerpt":"","text":"为了维护健壮性。 Idea捕获异常快捷键ctrl+alt+t。语法try{语句}catch(Exception e){异常处理} 异常事件:Error:JVM无法处理的严重问题，如栈溢出，内存不足。Exception:编程错误或偶然因素导致的一般问题。如空指针，文件不存在。Exception分为运行时异常和编译时异常。运行时异常可以暂时不用处理(太多)，编译时异常必须处理(如文件不存在，类不存在)。 空指针异常:运行时异常，使用对象对象为空。 数学运算异常:例如除以0。 数组越界异常 类型转换异常:试图把对象强制转化为不是实例的子类。 数字格式异常:字符串转化为数字，但是该字符串不满足时。 异常处理方式:try-catch-finally:程序员自行处理异常。throws:将异常抛出，由调用者处理。最顶级的调用者是JVM(main) try-catch-finally过程:异常发生时，系统将异常封装为Exception对象e，传递给catch。有没有发生异常都执行finally。故经常将释放资源的代码放在finally。 throws机制:层层往上扔。throws是放在方法的后边，如果出错就会throws。 finally一定会执行，就算前面有return了，finally也会执行。如果没有catch，那么finally执行完就结束了(因为没有捕捉到错误，错误发生，程序崩溃)","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://gladiouszhang.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"Java","slug":"Java","permalink":"http://gladiouszhang.github.io/tags/Java/"}]},{"title":"摄影分享","slug":"摄影分享","date":"2024-04-11T08:31:03.000Z","updated":"2024-07-31T16:07:34.000Z","comments":true,"path":"2024/04/11/摄影分享/","permalink":"http://gladiouszhang.github.io/2024/04/11/%E6%91%84%E5%BD%B1%E5%88%86%E4%BA%AB/","excerpt":"","text":"","categories":[],"tags":[{"name":"摄影","slug":"摄影","permalink":"http://gladiouszhang.github.io/tags/%E6%91%84%E5%BD%B1/"}]},{"title":"Java学习笔记——面向对象，枚举类，注解","slug":"Java学习笔记——面向对象，枚举类，注解","date":"2024-04-06T08:28:27.000Z","updated":"2024-07-31T08:30:08.000Z","comments":true,"path":"2024/04/06/Java学习笔记——面向对象，枚举类，注解/","permalink":"http://gladiouszhang.github.io/2024/04/06/Java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%EF%BC%8C%E6%9E%9A%E4%B8%BE%E7%B1%BB%EF%BC%8C%E6%B3%A8%E8%A7%A3/","excerpt":"","text":"面向对象 类变量:static。所有的对象共享。jdk7及以前放在静态域，jdk8及以后放在堆。随着类的创建而加载，类的销毁而销毁。 类方法:static。直接通过类名调用，不用创建实例。 静态方法只能访问静态成员，非静态方法都可以访问。 main方法:Public static void main(String［］ args)。Public是为了JVM调用。static是为了调用时不需要创建对象。void代表没有返回值。args接收参数。 代码块:又叫初始化块，属于类的成员，类似于方法，将逻辑语句用{}包裹起来。加载类或创建对象时隐式调用。修饰符仅可选static。相当于另外一种形式的构造器。如果多个构造器有相同内容可以抽取出来放在代码块中，实现代码重用。 单例设计模式:保证在整个软件周期中某个类只存在一个对象实例，并且只提供一个取得其对象实例的方法。构造器私有化(防止直接new)，类的内部创建对象，向外暴露一个Public static方法getInstance。分为饿汉式和懒汉式。饿汉式是直接创建一个私有静态对象(构造器为私有)，提供一个公共的static方法返回对象。懒汉式是先在类中声明一个Private static的对象，在getInstance的时候判断对象是否为空，如果为空才创建对象。 final:修饰类，不能被继承;修饰属性，不能被修改;修饰变量，不能被修改。 抽象类:父类方法中含有abstract方法，这个类就是一个抽象类。抽象类不能被实例化。抽象类不一定有abstract方法，但一旦有abstract方法一定是抽象类。abstract只能修饰类和方法。抽象方法不能有主体。抽象类也可以被抽象类继承，子类如果不是抽象类，需要实现抽象类的所有抽象方法。 抽象类的最佳时机:模板设计模式。相当于给子类定下来了一些模板。 接口interface:更抽象的抽象类，jdk7及以前所有方法都没有方法体，jdk8及以后接口内可以有静态方法，默认方法，可以有方法的具体实现。接口类型可以接受实现了该接口的对象(多态)。接口存在多态传递，即A实现B接口，C继承A，则C耶实现了B接口。 内部类:在其他类的内部嵌套的类。类的五大成员:属性，方法，构造器，代码块，内部类。内部类可访问外部类的私有属性。定义在类的局部位置(方法，代码块)的有局部内部类和匿名内部类，定义在成员位置的有成员内部类和静态内部类。匿名内部类相对比较重要，即在new一个类(或接口)的时候定义参数与类体，没有具体的名字:new class(参数列表){类体}。 枚举类 枚举就是事先在类里面定义好对象。enum 类名{在最开始初始化枚举对象} 注解 注解:@Override:重写父类方法，@Deprecated:已过时，@SupressWarning:抑制警告。 元注解:注解的注解。Retention:注解的作用范围，包括SOURCE(只在源码)，CLASS(保留到CLASS文件中)，RUNTIME(保存到运行时)。Target:注解的作用对象。Documented:注解是否在javadoc体现。Inherited:子类是否继承父类注解。","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://gladiouszhang.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"Java","slug":"Java","permalink":"http://gladiouszhang.github.io/tags/Java/"}]},{"title":"mit6.824笔记","slug":"mit6-824笔记","date":"2024-03-31T08:20:53.000Z","updated":"2024-12-13T02:01:51.162Z","comments":true,"path":"2024/03/31/mit6-824笔记/","permalink":"http://gladiouszhang.github.io/2024/03/31/mit6-824%E7%AC%94%E8%AE%B0/","excerpt":"","text":"环境配置 lab1 阅读mrsequential.go 阅读wc.go 任务 阅读 mrcoordinator.go mrworker.go coordinator.go rpc.go worker.go 思路 新worker加入 master执行逻辑 worker执行逻辑 环境配置 环境：Ubuntu 20.04 配置go语言环境 1apt install golang 在vscode里面安装go的插件 lab1 .so文件是go里面的插件。在本lab中mrsequential.go是主程序。每次运行主程序的时候选择一个插件，即具体的map-reduce过程。 go build -buildmode=plugin …/mrapps/wc.go是吧wc.go编译成插件（动态链接库） 阅读mrsequential.go os.Args 是一个字符串切片，包含了程序运行时的所有命令行参数，包括程序名本身。程序需要至少两个参数：xxx.so 插件文件和至少一个输入文件。 如果合法，则加载插件中的map和reduce方法。 创建一个中间输出的键值对切片。 对于所有输入的文件，将其分别打开并全部读入，调用插件中的map函数，生成中间键值对，并将键值对的内容全部加入先前创建的中间输出切片。 如果要将一个切片的所有元素追加到另一个切片中，可以使用 ... 操作符。这个操作符告诉编译器将切片展开为一个个的元素。如果不使用 ...，则会尝试将整个切片作为一个元素添加到目标切片中。 与真实的MapReduce不同，这里的mrsequential.go将所有的中间数据都存储在一个切片中，而不是被切分成N*M个。 对key进行排序。 对于每一个中间输出的键值对，检查有多少个key相同，把相同的key数量统计为j，并将这j个相同key的键值对的value存入一个字符串切片，将这个相同的key和字符串切片传入自定义的reduce方法中，最后键值对结果保存到mr-out-0中。 具体的loadPlugin函数（即加载map和reduce方法的函数），用Lookup来寻找文件中的方法，返回该方法的引用。 1mapf := xmapf.(func(string, string) []mr.KeyValue) 这行代码通过类型断言将 xmapf 变量转换成具体的函数类型 func(string, string) []mr.KeyValue。这意味着程序预期找到的 &quot;Map&quot; 函数应该接受两个 string 类型的参数，并返回一个 mr.KeyValue 类型的切片。 Lookup返回一个空接口类型 interface&#123;&#125; 。可以理解空接口类型就像java中的object，所有类都继承他，但是具体是啥需要自行解释（断言），是一种多态的体现。如果断言错误就会出现恐慌（panic）。 阅读wc.go 实现了map和reduce方法。map读入文件名和以字符串形式传入的文件内容，实际上并没有用到文件名。 在map方法中，首先创建了一个判断分隔符的函数，将其作为回调函数来分割文件内容，返回一个个索引和单词组成的切片。遍历切片，将所有的单词用“单词: 1”的键值对存储在切片中。返回切片。 reduce方法直接返回了values的长度。 任务 实现一个分布式 MapReduce，它由两个程序（coordinator和worker）组成。只有一个协调程序和一个或多个并行执行的工作程序。在真实系统中，worker会运行在多台不同的机器上，但在本lab中，你将在一台机器上运行所有worker。worker将通过 RPC 与协调程序对话。每个 worker 进程将循环向coordinator请求任务，从一个或多个文件中读取任务输入，执行任务，将任务输出写入一个或多个文件，然后再次向coordinator请求新任务。coordinator应该注意到，如果某个 worker 在合理的时间内（本lab使用 10 秒）没有完成任务，就会将相同的任务交给不同的 worker 。 提供的代码位于main/mrcoordinator.go 和main/mrworker.go，最后实现的代码放在 mr/coordinator.go, mr/worker.go和 mr/rpc.go。 阅读 首先阅读一下源码。其中main/mrcoordinator.go 和main/mrworker.go是不能修改的，mrcoordinator.go用于调用自己编写的 mr/coordinator.go，mrworker.go用于开启一个worker进程，具体实现在mr/rpc.go。 mrcoordinator.go 调用了mr/coordinator.go，将所有文件名称传入MakeCoordinator方法，同时传入10，代表10个reduce任务。当Done返回true的时候结束。 mrworker.go 加载插件，生成map和reduce方法，传给自己创建的worker。 coordinator.go 创建了一个Coordinator类，主要包含server，Done方法。server方法用于开启一个接受RPC请求的线程。Done方法用于判断工作是否结束。MakeCoordinator函数被mrcoordinator.go调用，返回一个Coordinator&#123;&#125;的实例。 rpc.go RPC相关的一些定义，自定义时需要首字母大写。包含一个coordinatorSock() 函数，用于在/var/tmp/目录下创建一个套接字文件，名为5840-mr-UserId。这个函数并不直接创建，而是返回这样一个路径下命名的字符串。 worker.go 在其中定义了键值对的结构体。 创建了一个将不同键通过对其哈希值取模分配到N个reduce任务的方法。 最主要的是main/mrworker.go会调用的Worker方法，传入map和reduce方法，主要是在这里写代码。 思路 按照原论文的习惯，我就称为worker和master了 新worker加入 对于woker来说，可以每次一上线就注册到master当中，调用master的join方法（待编写） 1234567891011121314151617181920func (w *workerTask) CallMasterStart() &#123; args := ArgsToMaster&#123;&#125; args.Id = os.Getuid() fmt.Printf(&quot;id %v\\n&quot;, args.Id) //args.msgType = join reply := ArgsFromMaster&#123;&#125; ok := call(&quot;Coordinator.WorkerJoin&quot;, &amp;args, &amp;reply) if ok &#123; // 应该会返回master给返回worker的任务，待详细设计 //fmt.Printf(&quot;reply.msg %v\\n&quot;, reply.Msg) splits := strings.Split(reply.Msg, &quot;=&quot;) w.nReduce, _ = strconv.Atoi(splits[1]) w.filename = splits[0] w.taskType, _ = strconv.Atoi(splits[2]) //fmt.Printf(&quot;reply.msg %v, nReduce %v\\n&quot;, w.filename, w.nReduce) &#125; else &#123; fmt.Printf(&quot;call failed!\\n&quot;) &#125;&#125; join方法里面最好是能建立一个socket到worker，不知道可不可以，如果不可以的话，master怎么给woker派任务？（用reply的值返回就行，socket开销太大）所以在worker中： 1234567891011121314151617181920func (c *Coordinator) WorkerJoin(args *ArgsToMaster, reply *ArgsFromMaster) error &#123; // 由于是并发的，所以需要考虑线程安全 c.mu.Lock() c.workerList = append(c.workerList, args.Id) // 回传一个任务地址回去 for i, taskItem := range c.taskList &#123; //fmt.Println(taskItem) if taskItem.taskStatus == ready &#123; reply.Msg = taskItem.taskAddr + &quot;=&quot; + strconv.Itoa(c.nReducer) + &quot;=&quot; + strconv.Itoa(int(taskItem.taskType)) c.taskList[i].taskStatus = assign c.taskList[i].taskWorker = args.Id // 如果找到了就要解锁，不然其他线程获取不到锁 c.mu.Unlock() return nil &#125; &#125; c.mu.Unlock() reply.Msg = &quot;&quot; return nil&#125; master维护一个任务列表，每个任务包含任务类型，文件地址，任务状态，分配到的wokerid 123456type task struct &#123; taskType TaskType //任务类型 taskAddr string //文件地址 taskStatus TaskStatus //任务状态 taskWorker int //分配给的worker编号&#125; worker收到reply之后，应该在本地读取任务并运行 报错： 1gob: type mismatch: no fields matched compiling decoder for ArgsToMaster 搜了一下说客户端所传的参数类型和服务端不一致 原来是因为之前修改了结构体名称后没有重新运行master。。。。。 master执行逻辑 按理说master给worker分了任务就已经可以了，但是，master有要求如下： 如果工作者在合理的时间内（在这个实验中，使用十秒）没有完成其任务，协调者应该注意到，并将相同的任务分配给不同的工作者。 所以master应当给每个任务维护一个计时器，只要10s到了任务还没有end，那这个任务就应该把状态改为ready。任务新增计时器的字段，并且每分配一次任务就要初始化一次计时器 在master的任务列表初始化结束后，开启一个新的携程，专门用于检查是否超时。此后每次任务完成回给master的时候，master都应该检查id是不是和列表中的相同。 原本修改的代码： 1234567891011121314// 用来检查有没有任务超时了func (c *Coordinator) testTimeOut() &#123; for !c.Done() &#123; for i, taskItem := range c.taskList &#123; //fmt.Println(&quot;正在检查：&quot;, c.taskList[i]) if c.taskList[i].taskStatus == assign &amp;&amp; time.Since(c.taskList[i].taskStart) &gt;= 10*time.Second &#123; //fmt.Println(&quot;已到达&quot;) fmt.Println(&quot;删除了：&quot;, taskItem.taskAddr, time.Since(taskItem.taskStart), &quot;现在时间：&quot;, time.Now(), &quot;任务开始时间&quot;, c.taskList[i].taskStart) c.taskList[i].taskStatus = ready c.taskList[i].taskWorker = -1 &#125; &#125; &#125;&#125; 但是存在一个问题！就是在锁的机制上。简单地说，c里面的数据在多线程中是不安全的，每一个访问和修改都应该要加锁才对。 因此，在每一个if判断前后，都应该加上一个锁。但是这样是否就存在一个问题：所有的步骤都卡在这个锁上，降低了并行的效率，成为性能瓶颈。虽然在master上，这个锁并不一定会太影响，但是诸如检查任务是否超时的场景会经常请求访问。 所以我考虑不用之前定义的sync.Mutex，而是用读写锁RWMutex，这样至少可以多个同时读。最后写出来像这样： 1234567891011121314151617181920// 用来检查有没有任务超时了func (c *Coordinator) testTimeOut() &#123; for !c.Done() &#123; for i := range c.taskList &#123; //fmt.Println(&quot;正在检查：&quot;, c.taskList[i]) c.mu.RLock() if c.taskList[i].taskStatus == assign &amp;&amp; time.Since(c.taskList[i].taskStart) &gt;= 10*time.Second &#123; fmt.Println(&quot;已到达&quot;) c.mu.RUnlock() c.mu.Lock() fmt.Println(&quot;删除了：&quot;, c.taskList[i].taskAddr, time.Since(c.taskList[i].taskStart), &quot;现在时间：&quot;, time.Now(), &quot;任务开始时间&quot;, c.taskList[i].taskStart) c.taskList[i].taskStatus = ready c.taskList[i].taskWorker = -1 c.mu.Unlock() c.mu.RLock() // 为了和最后的c.mu.RUnlock()配对，不然会出错 &#125; c.mu.RUnlock() &#125; &#125;&#125; gpt 给了一版更好的，我也觉得更好看，但是我没有用： 12345678910111213141516171819202122func (c *Coordinator) testTimeOut() &#123; for !c.Done() &#123; for i := range c.taskList &#123; c.mu.RLock() task := c.taskList[i] // 获取任务 taskStatus := task.taskStatus taskStart := task.taskStart c.mu.RUnlock() if taskStatus == assign &amp;&amp; time.Since(taskStart) &gt;= 10*time.Second &#123; // 超时处理逻辑 c.mu.Lock() if c.taskList[i].taskStatus == assign &#123; // 双重检查避免竞态条件 fmt.Println(&quot;超时任务：&quot;, c.taskList[i].taskAddr, time.Since(taskStart)) c.taskList[i].taskStatus = ready c.taskList[i].taskWorker = -1 &#125; c.mu.Unlock() &#125; &#125; &#125;&#125; 在Done里面，我们可以简单的把任务队列过一遍，如果所有的任务都已经变成finish，那么done返回true 123456789101112131415161718// main/mrcoordinator.go calls Done() periodically to find out// if the entire job has finished.func (c *Coordinator) Done() bool &#123; ret := true // Your code here. // 遍历任务队列，如果存在为finish的，就返回false c.mu.RLock() for _, task := range c.taskList &#123; if task.taskStatus != finish &#123; ret = false &#125; &#125; c.mu.RUnlock() return ret&#125; worker执行逻辑 现在worker知道了任务类型和文件地址，应该使用map或者reduce函数进行操作，并将结果存到文件中。但仍然存在一个问题：我们并不是调完一次map或者reduce任务，worker就挂了，而是持续存在。因此，需要每执行完一个任务，就去找master要任务。","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://gladiouszhang.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"分布式系统","slug":"分布式系统","permalink":"http://gladiouszhang.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"}]}],"categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://gladiouszhang.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"强化学习","slug":"强化学习","permalink":"http://gladiouszhang.github.io/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"},{"name":"AI Infa","slug":"AI-Infa","permalink":"http://gladiouszhang.github.io/tags/AI-Infa/"},{"name":"分布式系统","slug":"分布式系统","permalink":"http://gladiouszhang.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"name":"边缘计算","slug":"边缘计算","permalink":"http://gladiouszhang.github.io/tags/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/"},{"name":"实习项目","slug":"实习项目","permalink":"http://gladiouszhang.github.io/tags/%E5%AE%9E%E4%B9%A0%E9%A1%B9%E7%9B%AE/"},{"name":"Java","slug":"Java","permalink":"http://gladiouszhang.github.io/tags/Java/"},{"name":"摄影","slug":"摄影","permalink":"http://gladiouszhang.github.io/tags/%E6%91%84%E5%BD%B1/"}]}